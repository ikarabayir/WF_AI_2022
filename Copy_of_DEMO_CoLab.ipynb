{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "c9af9726",
      "metadata": {
        "id": "c9af9726"
      },
      "source": [
        "# Prediction of HF within 10 years using Artificial Intelligence (End-to-End Implementation)\n",
        "## Agenda \n",
        "1. Introduction\n",
        "2. AI, more specfically Deep Learning\n",
        "3. Pre-requisities and Technology\n",
        "4. Prediction of HF within 10 years using Artificial Intelligence\n",
        "5. Data Overview, Exploratory Data Analysis with Pandas and NumPy\n",
        "6. Data split (Cross Validation) to have robust and generalizable AI model (Hyperparameter Tuning)\n",
        "7. Data Manipulation (Imputation if needed)\n",
        "8. Building and deploying DL model\n",
        "9. Feature extraction from DL model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "182d4100",
      "metadata": {
        "id": "182d4100"
      },
      "source": [
        "## Introduction\n",
        "\n",
        "Ibrahim Karabayir, PhD, is working on Dr.Akbilgic's lab as a research fellow, focused on to create solution CVD based problems and other clinical problems using AI, such as HF prediction, predction late onset Cardiomyopathy among Childhood Cancer, deep phenotyping HFpEF, predicting Parkinson's Disease risk using ECG and other clinical data, predicting rapid decline in kidney function, and much more. Dr. Karabayir is graduated from IStanbul University in 2018, which his PhD thesis focused on proposing swarm intelligence based optimization algorithm to optimize DL models, his study published in IEEE TNNLS (impact factor of 10.451)."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "49a85c4d",
      "metadata": {
        "id": "49a85c4d"
      },
      "source": [
        "## Artificial Intelligence in General and Deep Learning\n",
        "\n",
        "\n",
        "\n",
        "<table><tr>\n",
        "<td> <img src=\"800px-AI-ML-DL.svg.png\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
        "<td> <img src=\"deep-learning-2.jpg\" alt=\"Drawing\" style=\"width: 250px;\"/> </td>\n",
        "</tr></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "956ea433",
      "metadata": {
        "id": "956ea433"
      },
      "source": [
        "<table><tr>\n",
        "<td> <img src=\"visualization-of-the-neural-network.gif\" alt=\"Drawing\" style=\"width: 450px; height: 4000x\"/> </td>\n",
        "<td> <img src=\"KindAmpleImperialeagle-size_restricted.gif\" alt=\"Drawing\" style=\"width: 150px;  height: 10x\"/> </td>\n",
        "</tr></table>"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "14d7e74c",
      "metadata": {
        "id": "14d7e74c"
      },
      "source": [
        "## Pre-requisities and Technology\n",
        "\n",
        "There may be some technological barriers to build huge DL, like having GPU. DL libraries are making calculations using symbolic Tensors. These symbolic (declarative) API is written on GPU. With Symbolic APIs your model is a graph-like data structure\n",
        "Symbolic tensor differs from other tensors in that they do not specifically hold values.\n",
        "\n",
        "\n",
        "### Examples\n",
        "\n",
        "No values are explicitly being defined in the network. Rather, a framework is created for the input variables to be read by the network, and then generate predictions.\n",
        "\n",
        "```python\n",
        "import theano as th \n",
        "a = th.iscalar()\n",
        "b = th.iscalar()\n",
        "f = theano.function([a, b], a + b)\n",
        "f(10,32)\n",
        "\n",
        "\n",
        "from tensorflow.keras import models\n",
        "from tensorflow.keras import layers\n",
        "\n",
        "model = models.Sequential()\n",
        "model.add(layers.Dense(8, activation='relu', input_shape=(4,)))\n",
        "model.add(layers.Dense(1, activation='sigmoid'))\n",
        "\n",
        "\n",
        "```\n",
        "\n",
        "### Benefits of Symbolic APIs\n",
        "- Having huge capacity to run DL models efficently ans fast thanks to GPU\n",
        "- Able to display the model\n",
        "- Debugging happens in model building not during executions, it will provide that once the model compiled, it will run. (exception data)\n",
        "- Consistent API, it means model can be reusable and sharable. It is so important for transfer learning, and feature extraction from intermediate layers.\n",
        "- Easy tha clone and copy. You dont have to create the model from scratch, you can get same model, or same structure from another model.\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "bc736fcb",
      "metadata": {
        "id": "bc736fcb"
      },
      "source": [
        "## Prediction of HF within 10 years using Artificial Intelligence\n",
        "\n",
        "![graphical_abstract.jpg](attachment:graphical_abstract.jpg)\n",
        "\n",
        "- Data from the baseline visits (1987-89) of the Atherosclerosis Risk in Communities (ARIC) Study\n",
        "- The ARIC is an ongoing prospective epidemiologic study, designed to investigate the etiology of atherosclerosis and its clinical outcomes, and cardiovascular risk factors associated with demographics, race, gender and time\n",
        "- From 1987 to 1989 (visit 1, and considered as the baseline for our study), a total of 15,792 participants (8,710 women and 4,266 of black race) were enrolled and completed a home interview and clinic visit\n",
        "- An additional six follow-up clinic visits occurred, with visit 2 occurring between 1990-1992, visit 3 being held between 1993-1996 and visit 4 held between 1996 and 1998 reducing to 11,656 participants. Visit 5 was held in 2011-2013 and visits 6 and 7 occurring between 2017 and 2019.\n",
        "- In this study we utilize data from visit 1 to visit 4 in AI based models\n",
        "- Participants with good quality baseline ECG were included.\n",
        "- Participants with prevalent HF were excluded\n",
        "- Outcomes: Our main outcome was the prediction of new onset heart failure events within 10 years from visit 1 baseline examination.\n",
        "- ECG data: Raw digital ECG data (time-voltage) for 12 leads from the baseline (visit 1) were used. A supine 12-lead ECG at 250 Hz frequency of 10 seconds at rest was used\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "1a2cea0b",
      "metadata": {
        "id": "1a2cea0b"
      },
      "source": [
        "## Data Overview, Exploratory Data Analysis with Pandas and NumPy"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c4aa6be7",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c4aa6be7",
        "outputId": "48a15906-40c4-434f-deb6-a7c62d872a31"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ],
      "source": [
        "## Import necessary packages\n",
        "\n",
        "from __future__ import division\n",
        "\n",
        "\n",
        "\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "import glob\n",
        "import os\n",
        "import csv\n",
        "import joblib\n",
        "import pickle\n",
        "import sklearn as sk\n",
        "import joblib\n",
        "import pickle\n",
        "import tensorflow as tf\n",
        "import matplotlib.pyplot as plt\n",
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.metrics import confusion_matrix\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from sklearn.model_selection import train_test_split, StratifiedShuffleSplit\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from keras import models \n",
        "from keras import layers\n",
        "from keras import optimizers\n",
        "from keras import losses\n",
        "from keras import metrics\n",
        "import keras\n",
        "from keras.layers import Dense, Conv2D, Conv1D, BatchNormalization, Activation\n",
        "from keras.layers import MaxPooling1D, Input, Flatten\n",
        "from sklearn.utils import class_weight, compute_class_weight\n",
        "from sklearn.metrics import confusion_matrix, roc_curve, auc, f1_score\n",
        "from keras.models import Sequential\n",
        "from keras.layers.core import Dense, Activation, Flatten\n",
        "from keras import regularizers\n",
        "from keras.regularizers import l2\n",
        "from keras.layers import Dropout\n",
        "from keras.models import Model\n",
        "from keras.callbacks import ModelCheckpoint, LearningRateScheduler\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "from sklearn import preprocessing\n",
        "import seaborn as sns\n",
        "from keras.callbacks import ReduceLROnPlateau, EarlyStopping\n",
        "#from bayes_opt import BayesianOptimization\n",
        "from sklearn.model_selection import KFold,StratifiedKFold\n",
        "#from xgboost import XGBClassifier\n",
        "from scipy import signal\n",
        "from keras.utils import np_utils\n",
        "import keras.backend as K\n",
        "\n",
        "print(os.getcwd())\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive')\n",
        "\n",
        "!ls /content/gdrive/My\\ Drive"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tljwu1Eacom_",
        "outputId": "e9007701-f1ac-417f-ea53-0e041a19353e"
      },
      "id": "tljwu1Eacom_",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/gdrive; to attempt to forcibly remount, call drive.mount(\"/content/gdrive\", force_remount=True).\n",
            "'2016 kasım öncesi'\n",
            "'Chicago Zoological Society - membership_print.pdf'\n",
            " cifar100_resnet56_evgo3_deneme.ipynb\n",
            " Classroom\n",
            "'Colab Notebooks'\n",
            "'Copy of National Leaders Idioms_IK.gdoc'\n",
            " day1-3-17-2020.7z\n",
            " DEMO_WakeForest\n",
            " ecg_stjude\n",
            " IbrahimDataNew.xlsx\n",
            " IK0_10_5_25.h5\n",
            " IK1_10_5_28.h5\n",
            " IK2_10_5_17.h5\n",
            " IK3_10_5_21.h5\n",
            " IK4_10_5_37.h5\n",
            " lastdata.xlsx\n",
            " masaustu_drive\n",
            " MESAtest_1_500_12.npy\n",
            " MESAtest_GPUTF.ipynb\n",
            " MESAtest_GPUTF_lite.ipynb\n",
            " Models_CNN\n",
            " model.tflite\n",
            " my_excel_file_stand_coef.xlsx\n",
            " my_excel_file.xlsx\n",
            " optimizasyon_calismalar_11_mayis\n",
            " OzappleECG_MAIN_DATA.npy\n",
            " OzappleECG.npy\n",
            "'Revision_A Novel Learning Algorithm to Optimize Deep Neural Networks Evolved Gradient Direction Optimizer (EVGO)_v1.docx'\n",
            "'Revision_A Novel Learning Algorithm to Optimize Deep Neural Networks Evolved Gradient Direction Optimizer (EVGO)_v6.docx'\n",
            " tenant_ledger-ibrahim_karabayir_havvagul_karabayir-20210708.gdoc\n",
            " tenant_ledger-ibrahim_karabayir_havvagul_karabayir-20210708.pdf\n",
            " TF_ecg_PRED_oZ.ipynb\n",
            " Tf_risks.csv\n",
            " Untitled0.ipynb\n",
            " Untitled1.ipynb\n",
            "'WF STAFF Offer Letter Ibrahim Karabayir.pdf'\n",
            "'YÜKSEK LİSANS TEZ'\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content/gdrive/My\\ Drive/DEMO_WakeForest"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sqpa6GhQcw5M",
        "outputId": "19f9a84a-512c-4533-9caf-778c5ff9337e"
      },
      "id": "sqpa6GhQcw5M",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content/gdrive/My Drive/DEMO_WakeForest\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "123a4687",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "123a4687",
        "outputId": "1b323b70-9084-4b15-fb6c-11cba71dcf47"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Numpy version is  1.21.6\n",
            "TF version is  2.8.0\n",
            "Keras version is  2.8.0\n"
          ]
        }
      ],
      "source": [
        "# Check out versions of libraries we have\n",
        "print (\"Numpy version is \", np.__version__)\n",
        "print (\"TF version is \", tf.__version__)\n",
        "print (\"Keras version is \", keras.__version__)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ade79834",
      "metadata": {
        "id": "ade79834"
      },
      "source": [
        "### Data import"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "274b83b9",
      "metadata": {
        "id": "274b83b9"
      },
      "outputs": [],
      "source": [
        "# ECGs_raw = np.load(\"data/visit1_leads_sortedbyPID_14613.npy\", allow_pickle = True)[:1000]\n",
        "clinical_variables = pd.read_csv(\"clinicaldata_10yrs_final_dummy.csv\")[:1000]\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "3143621f",
      "metadata": {
        "id": "3143621f"
      },
      "outputs": [],
      "source": [
        "# ECGs=ECGs_raw[::,250:,]\n",
        "clinical_variables = clinical_variables.replace(to_replace=' ', value=np.nan, regex=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "0cd959b8",
      "metadata": {
        "id": "0cd959b8"
      },
      "source": [
        "### Explore the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "181bc2e1",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "181bc2e1",
        "outputId": "ac79440c-1601-4c6a-badf-3f849901c77c"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 18)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ],
      "source": [
        "#ECGs_raw.shape, ECGs.shape, \n",
        "clinical_variables.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "b71b0011",
      "metadata": {
        "scrolled": false,
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b71b0011",
        "outputId": "5269526a-c20d-466a-8e58-16bd2b864ae3"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "<class 'pandas.core.frame.DataFrame'>\n",
            "RangeIndex: 1000 entries, 0 to 999\n",
            "Data columns (total 18 columns):\n",
            " #   Column        Non-Null Count  Dtype  \n",
            "---  ------        --------------  -----  \n",
            " 0   ID            1000 non-null   int64  \n",
            " 1   male          1000 non-null   int64  \n",
            " 2   black         1000 non-null   int64  \n",
            " 3   V1AGE01       1000 non-null   int64  \n",
            " 4   DIABTS03      1000 non-null   int64  \n",
            " 5   HYPTMDCODE01  1000 non-null   int64  \n",
            " 6   BMI01         999 non-null    float64\n",
            " 7   sbp1          1000 non-null   float64\n",
            " 8   GLUSIU01      986 non-null    float64\n",
            " 9   CIGTYR01      972 non-null    object \n",
            " 10  PRVCHD05      1000 non-null   int64  \n",
            " 11  HDLSIU02      973 non-null    float64\n",
            " 12  CIGT01        997 non-null    float64\n",
            " 13  CLVH01        932 non-null    float64\n",
            " 14  LDLSIU02      957 non-null    float64\n",
            " 15  dbp1          1000 non-null   float64\n",
            " 16  afecgv1       1000 non-null   int64  \n",
            " 17  HF_10years    1000 non-null   int64  \n",
            "dtypes: float64(8), int64(9), object(1)\n",
            "memory usage: 140.8+ KB\n"
          ]
        }
      ],
      "source": [
        "clinical_variables.info()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "6628a54d",
      "metadata": {
        "id": "6628a54d"
      },
      "outputs": [],
      "source": [
        "clinical_variables['CIGTYR01'] = clinical_variables['CIGTYR01'].astype(float)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "2c818d9b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2c818d9b",
        "outputId": "857d9a21-d939-4981-9a99-14fc24124b3d"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "dtype('float64')"
            ]
          },
          "metadata": {},
          "execution_count": 22
        }
      ],
      "source": [
        "clinical_variables['CIGTYR01'].dtype"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7a41e476",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7a41e476",
        "outputId": "afb3ca8c-8e5a-4bb8-c415-63d774c79b96"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0    54.6\n",
              "1    45.4\n",
              "Name: male, dtype: float64"
            ]
          },
          "metadata": {},
          "execution_count": 23
        }
      ],
      "source": [
        "clinical_variables.male.value_counts() *100 / clinical_variables.shape[0] "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8735b67f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "8735b67f",
        "outputId": "0fd414fb-9850-4ee8-8dee-388e19819aa8"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "       ID  male  black  V1AGE01  DIABTS03  HYPTMDCODE01  BMI01   sbp1  \\\n",
              "0  100010     0      1       51         1             1  30.31  180.0   \n",
              "1  100047     0      0       60         0             0  25.75  149.0   \n",
              "2  100068     0      0       53         0             0  30.73  114.0   \n",
              "3  100079     0      1       47         1             1  34.81  124.0   \n",
              "4  100084     0      1       47         0             0  28.81  156.0   \n",
              "\n",
              "   GLUSIU01  CIGTYR01  PRVCHD05  HDLSIU02  CIGT01  CLVH01  LDLSIU02   dbp1  \\\n",
              "0     15.50     680.0         0      1.05     1.0     0.0      4.00  102.0   \n",
              "1      5.51       0.0         0      2.02     3.0     NaN      1.61   76.0   \n",
              "2      5.67     170.0         0      1.20     2.0     0.0      3.36   77.0   \n",
              "3     12.94       0.0         0      1.44     3.0     1.0      4.54   75.0   \n",
              "4      4.76       0.0         0      1.02     3.0     0.0      3.78   86.0   \n",
              "\n",
              "   afecgv1  HF_10years  \n",
              "0        0           0  \n",
              "1        0           0  \n",
              "2        0           0  \n",
              "3        0           0  \n",
              "4        0           0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-28ade026-4395-40c4-b02c-016add29df4f\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>ID</th>\n",
              "      <th>male</th>\n",
              "      <th>black</th>\n",
              "      <th>V1AGE01</th>\n",
              "      <th>DIABTS03</th>\n",
              "      <th>HYPTMDCODE01</th>\n",
              "      <th>BMI01</th>\n",
              "      <th>sbp1</th>\n",
              "      <th>GLUSIU01</th>\n",
              "      <th>CIGTYR01</th>\n",
              "      <th>PRVCHD05</th>\n",
              "      <th>HDLSIU02</th>\n",
              "      <th>CIGT01</th>\n",
              "      <th>CLVH01</th>\n",
              "      <th>LDLSIU02</th>\n",
              "      <th>dbp1</th>\n",
              "      <th>afecgv1</th>\n",
              "      <th>HF_10years</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>100010</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>51</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>30.31</td>\n",
              "      <td>180.0</td>\n",
              "      <td>15.50</td>\n",
              "      <td>680.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.05</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.00</td>\n",
              "      <td>102.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>100047</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>25.75</td>\n",
              "      <td>149.0</td>\n",
              "      <td>5.51</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>2.02</td>\n",
              "      <td>3.0</td>\n",
              "      <td>NaN</td>\n",
              "      <td>1.61</td>\n",
              "      <td>76.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>100068</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>53</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.73</td>\n",
              "      <td>114.0</td>\n",
              "      <td>5.67</td>\n",
              "      <td>170.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.20</td>\n",
              "      <td>2.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.36</td>\n",
              "      <td>77.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>100079</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "      <td>1</td>\n",
              "      <td>34.81</td>\n",
              "      <td>124.0</td>\n",
              "      <td>12.94</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.44</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>4.54</td>\n",
              "      <td>75.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>100084</td>\n",
              "      <td>0</td>\n",
              "      <td>1</td>\n",
              "      <td>47</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>28.81</td>\n",
              "      <td>156.0</td>\n",
              "      <td>4.76</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0</td>\n",
              "      <td>1.02</td>\n",
              "      <td>3.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>3.78</td>\n",
              "      <td>86.0</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-28ade026-4395-40c4-b02c-016add29df4f')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-28ade026-4395-40c4-b02c-016add29df4f button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-28ade026-4395-40c4-b02c-016add29df4f');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 24
        }
      ],
      "source": [
        "clinical_variables.head()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "184a3f49",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "184a3f49",
        "outputId": "2a4a4094-cefe-43b8-d8f4-5a68c59640f4"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "ID               0\n",
              "male             0\n",
              "black            0\n",
              "V1AGE01          0\n",
              "DIABTS03         0\n",
              "HYPTMDCODE01     0\n",
              "BMI01            1\n",
              "sbp1             0\n",
              "GLUSIU01        14\n",
              "CIGTYR01        28\n",
              "PRVCHD05         0\n",
              "HDLSIU02        27\n",
              "CIGT01           3\n",
              "CLVH01          68\n",
              "LDLSIU02        43\n",
              "dbp1             0\n",
              "afecgv1          0\n",
              "HF_10years       0\n",
              "dtype: int64"
            ]
          },
          "metadata": {},
          "execution_count": 25
        }
      ],
      "source": [
        "clinical_variables.isna().sum()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "713e80ac",
      "metadata": {
        "id": "713e80ac"
      },
      "source": [
        "It shows that We will need to impute the data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "fc5da537",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fc5da537",
        "outputId": "b495d45e-09f6-4b47-ec82-05908924187a"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(55, 0.055)"
            ]
          },
          "metadata": {},
          "execution_count": 26
        }
      ],
      "source": [
        "labels= clinical_variables['HF_10years']\n",
        "np.sum(labels), np.sum(labels)/len(labels)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "8b512f25",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 300
        },
        "id": "8b512f25",
        "outputId": "3b075f0d-42bd-42f2-cbe4-7ebbf1087231"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "              male        black      V1AGE01     DIABTS03  HYPTMDCODE01  \\\n",
              "count  1000.000000  1000.000000  1000.000000  1000.000000   1000.000000   \n",
              "mean      0.454000     0.235000    54.351000     0.103000      0.289000   \n",
              "std       0.498129     0.424211     5.694403     0.304111      0.453525   \n",
              "min       0.000000     0.000000    44.000000     0.000000      0.000000   \n",
              "25%       0.000000     0.000000    49.750000     0.000000      0.000000   \n",
              "50%       0.000000     0.000000    54.000000     0.000000      0.000000   \n",
              "75%       1.000000     0.000000    59.000000     0.000000      1.000000   \n",
              "max       1.000000     1.000000    66.000000     1.000000      1.000000   \n",
              "\n",
              "            BMI01         sbp1    GLUSIU01     CIGTYR01    PRVCHD05  \\\n",
              "count  999.000000  1000.000000  986.000000   972.000000  1000.00000   \n",
              "mean    27.775095   121.847000    5.925406   292.945473     0.04200   \n",
              "std      5.127203    18.003381    2.244252   400.765773     0.20069   \n",
              "min     16.750000    81.000000    2.990000     0.000000     0.00000   \n",
              "25%     24.305000   110.000000    5.080000     0.000000     0.00000   \n",
              "50%     27.050000   120.000000    5.400000    80.000000     0.00000   \n",
              "75%     30.425000   132.000000    5.880000   512.500000     0.00000   \n",
              "max     54.410000   208.000000   28.760000  2460.000000     1.00000   \n",
              "\n",
              "         HDLSIU02      CIGT01      CLVH01    LDLSIU02         dbp1  \\\n",
              "count  973.000000  997.000000  932.000000  957.000000  1000.000000   \n",
              "mean     1.333104    2.186560    0.021459    3.763406    75.680000   \n",
              "std      0.410936    0.797398    0.144987    1.021981    11.633182   \n",
              "min      0.300000    1.000000    0.000000    0.000000    41.000000   \n",
              "25%      1.050000    2.000000    0.000000    3.120000    68.000000   \n",
              "50%      1.270000    2.000000    0.000000    3.720000    75.000000   \n",
              "75%      1.540000    3.000000    0.000000    4.380000    82.000000   \n",
              "max      3.660000    3.000000    1.000000    8.550000   130.000000   \n",
              "\n",
              "           afecgv1  \n",
              "count  1000.000000  \n",
              "mean      0.001000  \n",
              "std       0.031623  \n",
              "min       0.000000  \n",
              "25%       0.000000  \n",
              "50%       0.000000  \n",
              "75%       0.000000  \n",
              "max       1.000000  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-75426d8b-c99d-49e9-a6b8-badfdf8e42ba\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>male</th>\n",
              "      <th>black</th>\n",
              "      <th>V1AGE01</th>\n",
              "      <th>DIABTS03</th>\n",
              "      <th>HYPTMDCODE01</th>\n",
              "      <th>BMI01</th>\n",
              "      <th>sbp1</th>\n",
              "      <th>GLUSIU01</th>\n",
              "      <th>CIGTYR01</th>\n",
              "      <th>PRVCHD05</th>\n",
              "      <th>HDLSIU02</th>\n",
              "      <th>CIGT01</th>\n",
              "      <th>CLVH01</th>\n",
              "      <th>LDLSIU02</th>\n",
              "      <th>dbp1</th>\n",
              "      <th>afecgv1</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>count</th>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>999.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>986.000000</td>\n",
              "      <td>972.000000</td>\n",
              "      <td>1000.00000</td>\n",
              "      <td>973.000000</td>\n",
              "      <td>997.000000</td>\n",
              "      <td>932.000000</td>\n",
              "      <td>957.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "      <td>1000.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>mean</th>\n",
              "      <td>0.454000</td>\n",
              "      <td>0.235000</td>\n",
              "      <td>54.351000</td>\n",
              "      <td>0.103000</td>\n",
              "      <td>0.289000</td>\n",
              "      <td>27.775095</td>\n",
              "      <td>121.847000</td>\n",
              "      <td>5.925406</td>\n",
              "      <td>292.945473</td>\n",
              "      <td>0.04200</td>\n",
              "      <td>1.333104</td>\n",
              "      <td>2.186560</td>\n",
              "      <td>0.021459</td>\n",
              "      <td>3.763406</td>\n",
              "      <td>75.680000</td>\n",
              "      <td>0.001000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>std</th>\n",
              "      <td>0.498129</td>\n",
              "      <td>0.424211</td>\n",
              "      <td>5.694403</td>\n",
              "      <td>0.304111</td>\n",
              "      <td>0.453525</td>\n",
              "      <td>5.127203</td>\n",
              "      <td>18.003381</td>\n",
              "      <td>2.244252</td>\n",
              "      <td>400.765773</td>\n",
              "      <td>0.20069</td>\n",
              "      <td>0.410936</td>\n",
              "      <td>0.797398</td>\n",
              "      <td>0.144987</td>\n",
              "      <td>1.021981</td>\n",
              "      <td>11.633182</td>\n",
              "      <td>0.031623</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>min</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>44.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>16.750000</td>\n",
              "      <td>81.000000</td>\n",
              "      <td>2.990000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>0.300000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>41.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>25%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>49.750000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>24.305000</td>\n",
              "      <td>110.000000</td>\n",
              "      <td>5.080000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.050000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.120000</td>\n",
              "      <td>68.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>50%</th>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>54.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>27.050000</td>\n",
              "      <td>120.000000</td>\n",
              "      <td>5.400000</td>\n",
              "      <td>80.000000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.270000</td>\n",
              "      <td>2.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>3.720000</td>\n",
              "      <td>75.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>75%</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>59.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>30.425000</td>\n",
              "      <td>132.000000</td>\n",
              "      <td>5.880000</td>\n",
              "      <td>512.500000</td>\n",
              "      <td>0.00000</td>\n",
              "      <td>1.540000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>4.380000</td>\n",
              "      <td>82.000000</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>max</th>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>66.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>54.410000</td>\n",
              "      <td>208.000000</td>\n",
              "      <td>28.760000</td>\n",
              "      <td>2460.000000</td>\n",
              "      <td>1.00000</td>\n",
              "      <td>3.660000</td>\n",
              "      <td>3.000000</td>\n",
              "      <td>1.000000</td>\n",
              "      <td>8.550000</td>\n",
              "      <td>130.000000</td>\n",
              "      <td>1.000000</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-75426d8b-c99d-49e9-a6b8-badfdf8e42ba')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-75426d8b-c99d-49e9-a6b8-badfdf8e42ba button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-75426d8b-c99d-49e9-a6b8-badfdf8e42ba');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 27
        }
      ],
      "source": [
        "features = clinical_variables.iloc[ :  ,  1 : -1]\n",
        "features.describe()"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "79550371",
      "metadata": {
        "id": "79550371"
      },
      "source": [
        "### Visualize an example ECG"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "bef29b6b",
      "metadata": {
        "scrolled": true,
        "id": "bef29b6b",
        "outputId": "2fe1e429-beb3-42e0-df93-85caa48555f6"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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\n",
            "text/plain": [
              "<Figure size 1800x504 with 1 Axes>"
            ]
          },
          "metadata": {
            "needs_background": "light"
          },
          "output_type": "display_data"
        }
      ],
      "source": [
        ""
      ]
    },
    {
      "cell_type": "markdown",
      "id": "3fd4900f",
      "metadata": {
        "id": "3fd4900f"
      },
      "source": [
        "### Resampling \n",
        "Make data upsampling for ECGs. Here we're artificially creating data to increase sampling frequency from 250Hz to 500Hz. You may need it to balance dataset from different sites or just by simply having more detailed input. We'll use scipy's signal function. For reference: https://docs.scipy.org/doc/scipy/reference/generated/scipy.signal.resample.html\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1615e4d5",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1615e4d5",
        "outputId": "e0ec34c8-6d84-4df8-a838-e45046ac5468"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[[-522.        , -527.07878833, -517.        , ...,\n",
              "         -525.11655363, -522.        , -519.30940411],\n",
              "        [-522.        , -525.9702311 , -527.        , ...,\n",
              "         -518.74799954, -512.        , -509.06470799],\n",
              "        [-512.        , -515.08330283, -517.        , ...,\n",
              "         -380.29993139, -254.        ,  -95.23241423],\n",
              "        ...,\n",
              "        [-390.        , -392.13981492, -390.        , ...,\n",
              "         -394.6264488 , -395.        , -395.10166897],\n",
              "        [-400.        , -403.73766825, -400.        , ...,\n",
              "         -415.68612985, -410.        , -403.56742017],\n",
              "        [-410.        , -417.68439488, -410.        , ...,\n",
              "         -444.66068023, -410.        , -281.31966992]],\n",
              "\n",
              "       [[-420.        , -389.66548231, -420.        , ...,\n",
              "         -412.90311989, -425.        , -432.70680538],\n",
              "        [-425.        , -417.92612142, -425.        , ...,\n",
              "         -387.29694362, -400.        , -411.4675621 ],\n",
              "        [-415.        , -417.73047756, -425.        , ...,\n",
              "         -391.75602063, -395.        , -396.81125189],\n",
              "        ...,\n",
              "        [ 254.        ,  253.79086919,  254.        , ...,\n",
              "          259.75429207,  259.        ,  258.77419715],\n",
              "        [ 259.        ,  257.39594383,  254.        , ...,\n",
              "          247.59684867,  244.        ,  239.96465553],\n",
              "        [ 239.        ,  239.93171484,  239.        , ...,\n",
              "          264.39156094,  259.        ,  241.20707929]],\n",
              "\n",
              "       [[ 717.        ,  745.46699551,  703.        , ...,\n",
              "          636.04655122,  610.        ,  588.89569513],\n",
              "        [ 586.        ,  581.74615925,  561.        , ...,\n",
              "          465.02830159,  454.        ,  449.28759008],\n",
              "        [ 449.        ,  437.82478562,  415.        , ...,\n",
              "          381.02926406,  376.        ,  366.89976511],\n",
              "        ...,\n",
              "        [ -78.        ,  -82.90585531,  -78.        , ...,\n",
              "          -76.86166098,  -68.        ,  -60.06537871],\n",
              "        [ -68.        ,  -76.3877924 ,  -68.        , ...,\n",
              "          -70.03664733,  -54.        ,  -37.32645414],\n",
              "        [ -54.        ,  -73.77023362,  -54.        , ...,\n",
              "         -136.74356585,  -54.        ,  245.80140195]],\n",
              "\n",
              "       ...,\n",
              "\n",
              "       [[ -44.        ,  -41.98672947,  -44.        , ...,\n",
              "          -28.7931616 ,  -39.        ,  -43.85303958],\n",
              "        [ -39.        ,  -34.03286049,  -39.        , ...,\n",
              "          -46.11300698,  -39.        ,  -35.88288748],\n",
              "        [ -39.        ,  -42.85530937,  -44.        , ...,\n",
              "          -46.4058506 ,  -49.        ,  -51.19376047],\n",
              "        ...,\n",
              "        [ -78.        ,  -78.63057742,  -78.        , ...,\n",
              "          -78.79616428,  -78.        ,  -77.12315848],\n",
              "        [ -78.        ,  -78.9798036 ,  -78.        , ...,\n",
              "          -80.0251703 ,  -78.        ,  -75.00846264],\n",
              "        [ -78.        ,  -85.3970783 ,  -88.        , ...,\n",
              "          -81.23069749,  -78.        ,  -64.01963534]],\n",
              "\n",
              "       [[ -10.        ,   20.19728623,  -24.        , ...,\n",
              "          -23.61202642,  -34.        ,  -48.20106106],\n",
              "        [ -49.        ,  -48.12602857,  -59.        , ...,\n",
              "          -86.54270199,  -93.        ,  -98.96819929],\n",
              "        [ -98.        ,  -96.1239905 ,  -98.        , ...,\n",
              "          -90.89041081,  -93.        ,  -94.76286328],\n",
              "        ...,\n",
              "        [ 132.        ,  117.49955473,   98.        , ...,\n",
              "           14.2846375 ,   10.        ,    3.8200105 ],\n",
              "        [  -5.        ,  -14.12080587,  -20.        , ...,\n",
              "          -46.22785188,  -54.        ,  -61.74514101],\n",
              "        [ -63.        ,  -59.99140381,  -59.        , ...,\n",
              "          -37.00516653,  -44.        ,  -66.70149399]],\n",
              "\n",
              "       [[ -44.        ,  -40.76623828,  -34.        , ...,\n",
              "          -41.59523904,  -34.        ,  -26.68041688],\n",
              "        [ -24.        ,  -26.94919177,  -34.        , ...,\n",
              "          -37.52361009,  -39.        ,  -38.97313685],\n",
              "        [ -39.        ,  -39.14223345,  -39.        , ...,\n",
              "          -47.28985595,  -49.        ,  -49.3033128 ],\n",
              "        ...,\n",
              "        [ -44.        ,  -44.02597844,  -44.        , ...,\n",
              "          -52.46896956,  -54.        ,  -53.70897388],\n",
              "        [ -54.        ,  -54.63465692,  -54.        , ...,\n",
              "          -55.03728835,  -54.        ,  -54.36629589],\n",
              "        [ -59.        ,  -62.54652009,  -59.        , ...,\n",
              "          -72.07253821,  -63.        ,  -29.65285248]]])"
            ]
          },
          "metadata": {},
          "execution_count": 28
        }
      ],
      "source": [
        "ECGs_resampled = np.random.rand(1000,4500,12)\n",
        "ECGs_resampled"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "23702047",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "23702047",
        "outputId": "01c57a4a-7cd9-45d2-c8d4-07b532d92cb0"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(1000, 4500, 12)"
            ]
          },
          "metadata": {},
          "execution_count": 29
        }
      ],
      "source": [
        "ECGs_resampled.shape"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "931221ae",
      "metadata": {
        "id": "931221ae"
      },
      "source": [
        "## Data split (Cross Validation) to have robust and generalizable AI model (Hyperparameter Tuning)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "1ae6f48e",
      "metadata": {
        "id": "1ae6f48e"
      },
      "outputs": [],
      "source": [
        "X_CV, X_holdout, Feat_CV, Feat_holdout, y_CV, y_holdout = train_test_split(ECGs_resampled, features, labels,\n",
        "                                                                           test_size=0.20, random_state=0, stratify = labels)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "9df8fc8b",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9df8fc8b",
        "outputId": "698f3ddc-f687-474c-f261-cc84635c86c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(CV set) Number of samples: 800 and (CV set) Number of cases: 44\n",
            "(Holdout set) Number of samples: 200 and (Holdout set) Number of cases: 11\n"
          ]
        }
      ],
      "source": [
        "print (\"(CV set) Number of samples: \" + str(len(X_CV)) + \" and (CV set) Number of cases: \"+  str(np.sum(y_CV)))\n",
        "print (\"(Holdout set) Number of samples: \" + str(len(X_holdout)) + \" and (Holdout set) Number of cases: \"+  str(np.sum(y_holdout)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "223288fd",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "223288fd",
        "outputId": "4cddf002-763c-4904-ee95-4b32e52477aa"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "starting to split\n",
            "fold_cv_ 0\n",
            "(Train set) Number of samples: 640(Train set) Number of cases: 36\n",
            "(Validation set) Number of samples: 160(Validation set) Number of cases: 8\n",
            "fold_cv_ 1\n",
            "(Train set) Number of samples: 640(Train set) Number of cases: 35\n",
            "(Validation set) Number of samples: 160(Validation set) Number of cases: 9\n",
            "fold_cv_ 2\n",
            "(Train set) Number of samples: 640(Train set) Number of cases: 35\n",
            "(Validation set) Number of samples: 160(Validation set) Number of cases: 9\n",
            "fold_cv_ 3\n",
            "(Train set) Number of samples: 640(Train set) Number of cases: 35\n",
            "(Validation set) Number of samples: 160(Validation set) Number of cases: 9\n",
            "fold_cv_ 4\n",
            "(Train set) Number of samples: 640(Train set) Number of cases: 35\n",
            "(Validation set) Number of samples: 160(Validation set) Number of cases: 9\n"
          ]
        }
      ],
      "source": [
        "skf = StratifiedKFold(n_splits=5, random_state = 42, shuffle = True)\n",
        "\n",
        "\n",
        "TRA_X = []\n",
        "feat_TRA_X = []\n",
        "TRA_Y = []\n",
        "\n",
        "VAL_X = []\n",
        "feat_VAL_X = []\n",
        "VAL_Y = []\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "print ('starting to split')\n",
        "\n",
        "for fold_cv_, (tr_idx, val_idx) in enumerate(skf.split(X_CV, y_CV)):\n",
        "    strLog = \"fold_cv_ {}\".format(fold_cv_)\n",
        "    print(strLog)\n",
        "\n",
        "    trax = X_CV[tr_idx]\n",
        "    tray= y_CV.iloc[tr_idx]\n",
        "    feat_tra_x=Feat_CV.iloc[tr_idx]\n",
        "\n",
        "    valx = X_CV[val_idx]\n",
        "    valy= y_CV.iloc[val_idx]\n",
        "    feat_val_x=Feat_CV.iloc[val_idx]\n",
        "\n",
        "    print (\"(Train set) Number of samples: \" + str(len(trax)) + \"(Train set) Number of cases: \"+  str(np.sum(tray)))\n",
        "    TRA_X.append(trax)\n",
        "    TRA_Y.append(tray)\n",
        "    print (\"(Validation set) Number of samples: \" + str(len(valx)) + \"(Validation set) Number of cases: \" + str(np.sum(valy)))\n",
        "\n",
        "    VAL_X.append(valx)\n",
        "    VAL_Y.append(valy)\n",
        "\n",
        "    feat_TRA_X.append(feat_tra_x)\n",
        "    feat_VAL_X.append(feat_val_x)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e626e2a4",
      "metadata": {
        "id": "e626e2a4"
      },
      "source": [
        "# Building and deploying DL model"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "759904e0",
      "metadata": {
        "id": "759904e0"
      },
      "source": [
        "### Define the Deep Learning Model\n",
        "\n",
        "- The use of this residual learning framework helps to ease the optimization of the models by developing models that gain better accuracy when compared to ‘more traditional’ or ‘simplified’ deep networks. We excluded the first second of the 10-second ECGs from the data to eliminate the irregularity in the data since these sections were frequently associated with noise.\n",
        "- We then inputted the remaining 9 seconds of ECG that were up-sampled to a 500 Hz rate into the CNN model.\n",
        "- The CNN model was adapted to learn the abstract representations of a 12-lead ECG in order to predict HF by utilizing 1-dimensional convolution layers\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "90aba21a",
      "metadata": {
        "id": "90aba21a"
      },
      "source": [
        "### How Conv1d works?\n",
        "\n",
        "- Element-wise multiplication\n",
        "- Sliding over the input, \n",
        "- Slide, the kernel size, the start and end point of the kernel are hyper parameters\n",
        "- Inintialization method needs to be defined\n",
        "\n",
        "![Conv1d.gif](attachment:Conv1d.gif)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "e24db95e",
      "metadata": {
        "id": "e24db95e"
      },
      "source": [
        "![ecg_ai_arc.png](attachment:ecg_ai_arc.png)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "287c5e7f",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "287c5e7f",
        "outputId": "963fd459-b2b6-4b79-9940-d2c893c61840"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 4500, 12)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 4500, 16)     592         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 4500, 16)    64          ['conv1d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 4500, 16)     0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 4500, 16)     784         ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 4500, 16)    64          ['conv1d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 4500, 16)     0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 4500, 16)     784         ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 4500, 16)    64          ['conv1d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 4500, 16)     0           ['leaky_re_lu[0][0]',            \n",
            "                                                                  'batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 4500, 16)     0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 2250, 16)     0           ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2250, 16)     0           ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 2250, 16)     784         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 2250, 16)    64          ['conv1d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 2250, 16)     0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 2250, 16)     784         ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 2250, 16)    64          ['conv1d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 2250, 16)     0           ['dropout[0][0]',                \n",
            "                                                                  'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 2250, 16)     0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 1125, 16)    0           ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 1125, 16)     0           ['max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 563, 32)      1568        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 563, 32)     128         ['conv1d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 563, 32)      0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 563, 32)      3104        ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 563, 32)      544         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 563, 32)     128         ['conv1d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 563, 32)      0           ['conv1d_7[0][0]',               \n",
            "                                                                  'batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 563, 32)      0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_2 (MaxPooling1D)  (None, 281, 32)     0           ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 281, 32)      0           ['max_pooling1d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 281, 32)      3104        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 281, 32)     128         ['conv1d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 281, 32)      0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 281, 32)      3104        ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 281, 32)     128         ['conv1d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 281, 32)      0           ['dropout_2[0][0]',              \n",
            "                                                                  'batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 281, 32)      0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_3 (MaxPooling1D)  (None, 140, 32)     0           ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 140, 32)      0           ['max_pooling1d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 70, 64)       6208        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 70, 64)      256         ['conv1d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 70, 64)       0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 70, 64)       12352       ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 70, 64)       2112        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 70, 64)      256         ['conv1d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 70, 64)       0           ['conv1d_12[0][0]',              \n",
            "                                                                  'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 70, 64)       0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_4 (MaxPooling1D)  (None, 35, 64)      0           ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 35, 64)       0           ['max_pooling1d_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 35, 64)       12352       ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 35, 64)      256         ['conv1d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 35, 64)       0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 35, 64)       12352       ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 35, 64)      256         ['conv1d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 35, 64)       0           ['dropout_4[0][0]',              \n",
            "                                                                  'batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_12 (LeakyReLU)     (None, 35, 64)       0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_5 (MaxPooling1D)  (None, 17, 64)      0           ['leaky_re_lu_12[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 17, 64)       0           ['max_pooling1d_5[0][0]']        \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 1088)         0           ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2)            2178        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 64,562\n",
            "Trainable params: 63,634\n",
            "Non-trainable params: 928\n",
            "__________________________________________________________________________________________________\n"
          ]
        }
      ],
      "source": [
        "from keras.regularizers import l1,l2\n",
        "from keras.layers import LeakyReLU\n",
        "from keras.layers.noise import AlphaDropout\n",
        "from keras.layers.wrappers import TimeDistributed\n",
        "import sys\n",
        "nop = 4500\n",
        "\n",
        "\n",
        "def auc_roc(y_true, y_pred):\n",
        "    auc = tf.metrics.auc(y_true, y_pred)[1]\n",
        "    K.get_session().run(tf.local_variables_initializer())\n",
        "    return auc\n",
        "\n",
        "\n",
        "# In[45]:\n",
        "\n",
        "\n",
        "n = 2\n",
        "\n",
        "# Model version\n",
        "# Orig paper: version = 1 (ResNet v1), Improved ResNet: version = 2 (ResNet v2)\n",
        "version = 1\n",
        "\n",
        "# Computed depth from supplied model parameter n\n",
        "depth = n * 6 + 2\n",
        "\n",
        "\n",
        "# Model name, depth and version\n",
        "model_type = 'ResNet%dv%d' % (depth, version)\n",
        "input_shape = (nop,12)\n",
        "\n",
        "def lr_schedule(epoch):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    lr = 1e-3\n",
        "    if epoch > 60:\n",
        "        lr *= 0.5e-3\n",
        "    elif epoch > 45:\n",
        "        lr *= 1e-3\n",
        "    elif epoch > 30:\n",
        "        lr *= 1e-2\n",
        "    elif epoch > 15:\n",
        "        lr *= 1e-1\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n",
        "\n",
        "\n",
        "def resnet_layer(inputs,\n",
        "                 num_filters=16,\n",
        "                 kernel_size=3,\n",
        "                 strides=1,\n",
        "                 activation= 'relu',\n",
        "                 batch_normalization=True,\n",
        "                 conv_first=True):\n",
        "    \"\"\"2D Convolution-Batch Normalization-Activation stack builder\n",
        "\n",
        "    # Arguments\n",
        "        inputs (tensor): input tensor from input image or previous layer\n",
        "        num_filters (int): Conv2D number of filters\n",
        "        kernel_size (int): Conv2D square kernel dimensions\n",
        "        strides (int): Conv2D square stride dimensions\n",
        "        activation (string): activation name\n",
        "        batch_normalization (bool): whether to include batch normalization\n",
        "        conv_first (bool): conv-bn-activation (True) or\n",
        "            bn-activation-conv (False)\n",
        "\n",
        "    # Returns\n",
        "        x (tensor): tensor as input to the next layer\n",
        "    \"\"\"\n",
        "    conv = Conv1D(num_filters,\n",
        "                  kernel_size=kernel_size,\n",
        "                  strides=strides,\n",
        "                  padding='same',\n",
        "                  kernel_initializer='he_normal',\n",
        "                  kernel_regularizer=l2(1e-4))\n",
        "\n",
        "    x = inputs\n",
        "    if conv_first:\n",
        "        x = conv(x)\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = LeakyReLU(alpha=0.1)(x)\n",
        "            #x = Activation(activation)(x)\n",
        "    else:\n",
        "        if batch_normalization:\n",
        "            x = BatchNormalization()(x)\n",
        "        if activation is not None:\n",
        "            x = LeakyReLU(alpha=0.1)(x)\n",
        "            #x = Activation(activation)(x)\n",
        "        x = conv(x)\n",
        "    return x\n",
        "\n",
        "\n",
        "def resnet_v1(input_shape, depth, num_classes=2):\n",
        "    \"\"\"ResNet Version 1 Model builder [a]\n",
        "\n",
        "    Stacks of 2 x (3 x 3) Conv2D-BN-ReLU\n",
        "    Last ReLU is after the shortcut connection.\n",
        "    At the beginning of each stage, the feature map size is halved (downsampled)\n",
        "    by a convolutional layer with strides=2, while the number of filters is\n",
        "    doubled. Within each stage, the layers have the same number filters and the\n",
        "    same number of filters.\n",
        "    Features maps sizes:\n",
        "    stage 0: 32x32, 16\n",
        "    stage 1: 16x16, 32\n",
        "    stage 2:  8x8,  64\n",
        "    The Number of parameters is approx the same as Table 6 of [a]:\n",
        "    ResNet20 0.27M\n",
        "    ResNet32 0.46M\n",
        "    ResNet44 0.66M\n",
        "    ResNet56 0.85M\n",
        "    ResNet110 1.7M\n",
        "\n",
        "    # Arguments\n",
        "        input_shape (tensor): shape of input image tensor\n",
        "        depth (int): number of core convolutional layers\n",
        "        num_classes (int): number of classes (CIFAR10 has 10)\n",
        "\n",
        "    # Returns\n",
        "        model (Model): Keras model instance\n",
        "    \"\"\"\n",
        "    if (depth - 2) % 6 != 0:\n",
        "        raise ValueError('depth should be 6n+2 (eg 20, 32, 44 in [a])')\n",
        "    # Start model definition.\n",
        "    num_filters = 16\n",
        "    num_res_blocks = int((depth - 2) / 6)\n",
        "\n",
        "    inputs = Input(shape=input_shape)\n",
        "    x = resnet_layer(inputs=inputs)\n",
        "    # Instantiate the stack of residual units\n",
        "    for stack in range(3):\n",
        "        for res_block in range(num_res_blocks):\n",
        "            strides = 1\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                strides = 2  # downsample\n",
        "            y = resnet_layer(inputs=x,\n",
        "                             num_filters=num_filters,\n",
        "                             strides=strides)\n",
        "            y = resnet_layer(inputs=y,\n",
        "                             num_filters=num_filters,\n",
        "                             activation=None)\n",
        "            if stack > 0 and res_block == 0:  # first layer but not first stack\n",
        "                # linear projection residual shortcut connection to match\n",
        "                # changed dims\n",
        "                x = resnet_layer(inputs=x,\n",
        "                                 num_filters=num_filters,\n",
        "                                 kernel_size=1,\n",
        "                                 strides=strides,\n",
        "                                 activation=None,\n",
        "                                 batch_normalization=False)\n",
        "            x = keras.layers.add([x, y])\n",
        "            x = LeakyReLU(alpha=0.1)(x)\n",
        "            x = MaxPooling1D(pool_size=2)(x)\n",
        "            x = Dropout(0.1)(x)\n",
        "        num_filters *= 2\n",
        "\n",
        "    # Add classifier on top.\n",
        "    # v1 does not use BN after last shortcut connection-ReLU\n",
        "    #x = MaxPooling1D(pool_size=8)(x)\n",
        "    y = Flatten()(x)\n",
        "    outputs = Dense(num_classes,\n",
        "                    activation='softmax',\n",
        "                    kernel_initializer='he_normal')(y)\n",
        "\n",
        "    # Instantiate model.\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    model.summary()\n",
        "    return model\n",
        "\n",
        "\n",
        "model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "a7086bfb",
      "metadata": {
        "id": "a7086bfb"
      },
      "source": [
        "### Custom Callbacks"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "ef33d850",
      "metadata": {
        "id": "ef33d850"
      },
      "outputs": [],
      "source": [
        "import logging\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "from keras.callbacks import Callback\n",
        "\n",
        "class val_auc(Callback):\n",
        "    def __init__(self, validation_data=(), interval=1):\n",
        "        super(Callback, self).__init__()\n",
        "        super(val_auc, self).__init__()\n",
        "        \n",
        "        \n",
        "        self.interval = interval\n",
        "        self.X_val, self.y_val = validation_data\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        logs['val_auc'] = float('-inf')\n",
        "        \n",
        "        if epoch % self.interval == 0:\n",
        "            y_pred = self.model.predict(self.X_val, verbose=0)\n",
        "            score = roc_auc_score(self.y_val, y_pred)\n",
        "            print (\"Result for validatin set - epoch: {:d} - score: {:.6f}\".format(epoch, score))\n",
        "            logging.info(\"interval evaluation - epoch: {:d} - score: {:.6f}\".format(epoch, score))\n",
        "            logs['val_auc'] = score\n",
        "            \n",
        "class TestCallback(keras.callbacks.Callback):\n",
        "    def __init__(self, test_data):\n",
        "        self.test_data = test_data\n",
        "\n",
        "    def on_epoch_end(self, epoch, logs={}):\n",
        "        x, y = self.test_data\n",
        "        yhat = self.model.predict(x,verbose=0)\n",
        "        \n",
        "        auc = roc_auc_score(y_test, yhat)\n",
        "        \n",
        "        print('Testing Auc: ' + str(auc))\n",
        "        \n",
        "\n",
        "\n",
        "def lr_scheduler(epoch, lr):\n",
        "    \"\"\"Learning Rate Schedule\n",
        "\n",
        "    Learning rate is scheduled to be reduced after 80, 120, 160, 180 epochs.\n",
        "    Called automatically every epoch as part of callbacks during training.\n",
        "\n",
        "    # Arguments\n",
        "        epoch (int): The number of epochs\n",
        "\n",
        "    # Returns\n",
        "        lr (float32): learning rate\n",
        "    \"\"\"\n",
        "    if epoch > 80:\n",
        "        lr = 1e-5\n",
        "    elif epoch > 100:\n",
        "        lr = 5e-5\n",
        "    elif epoch > 75:\n",
        "        lr = 1e-4\n",
        "    elif epoch > 50:\n",
        "        lr = 5e-4\n",
        "    print('Learning rate: ', lr)\n",
        "    return lr\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "7f8b32d3",
      "metadata": {
        "id": "7f8b32d3"
      },
      "outputs": [],
      "source": [
        "scores_1 = []\n",
        "scores_2 = []\n",
        "acc_val_per_fold = []\n",
        "acc_per_fold = []\n",
        "loss_per_fold = []\n",
        "predict_df = []\n",
        "epoch = 5\n",
        "batch_size = 64\n",
        "num_classes = 2\n",
        "verbosity = 1\n",
        "input_shape = (4500,12)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "c330b28a",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c330b28a",
        "outputId": "6832f9a7-9dde-4f5f-9af3-2d216223c679"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model_2\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_3 (InputLayer)           [(None, 4500, 12)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d_30 (Conv1D)             (None, 4500, 16)     592         ['input_3[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_26 (BatchN  (None, 4500, 16)    64          ['conv1d_30[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_26 (LeakyReLU)     (None, 4500, 16)     0           ['batch_normalization_26[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_31 (Conv1D)             (None, 4500, 16)     784         ['leaky_re_lu_26[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_27 (BatchN  (None, 4500, 16)    64          ['conv1d_31[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_27 (LeakyReLU)     (None, 4500, 16)     0           ['batch_normalization_27[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_32 (Conv1D)             (None, 4500, 16)     784         ['leaky_re_lu_27[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_28 (BatchN  (None, 4500, 16)    64          ['conv1d_32[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_12 (Add)                   (None, 4500, 16)     0           ['leaky_re_lu_26[0][0]',         \n",
            "                                                                  'batch_normalization_28[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_28 (LeakyReLU)     (None, 4500, 16)     0           ['add_12[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_12 (MaxPooling1D  (None, 2250, 16)    0           ['leaky_re_lu_28[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_12 (Dropout)           (None, 2250, 16)     0           ['max_pooling1d_12[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_33 (Conv1D)             (None, 2250, 16)     784         ['dropout_12[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_29 (BatchN  (None, 2250, 16)    64          ['conv1d_33[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_29 (LeakyReLU)     (None, 2250, 16)     0           ['batch_normalization_29[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_34 (Conv1D)             (None, 2250, 16)     784         ['leaky_re_lu_29[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_30 (BatchN  (None, 2250, 16)    64          ['conv1d_34[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_13 (Add)                   (None, 2250, 16)     0           ['dropout_12[0][0]',             \n",
            "                                                                  'batch_normalization_30[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_30 (LeakyReLU)     (None, 2250, 16)     0           ['add_13[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_13 (MaxPooling1D  (None, 1125, 16)    0           ['leaky_re_lu_30[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_13 (Dropout)           (None, 1125, 16)     0           ['max_pooling1d_13[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_35 (Conv1D)             (None, 563, 32)      1568        ['dropout_13[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_31 (BatchN  (None, 563, 32)     128         ['conv1d_35[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_31 (LeakyReLU)     (None, 563, 32)      0           ['batch_normalization_31[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_36 (Conv1D)             (None, 563, 32)      3104        ['leaky_re_lu_31[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_37 (Conv1D)             (None, 563, 32)      544         ['dropout_13[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_32 (BatchN  (None, 563, 32)     128         ['conv1d_36[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_14 (Add)                   (None, 563, 32)      0           ['conv1d_37[0][0]',              \n",
            "                                                                  'batch_normalization_32[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_32 (LeakyReLU)     (None, 563, 32)      0           ['add_14[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_14 (MaxPooling1D  (None, 281, 32)     0           ['leaky_re_lu_32[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_14 (Dropout)           (None, 281, 32)      0           ['max_pooling1d_14[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_38 (Conv1D)             (None, 281, 32)      3104        ['dropout_14[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_33 (BatchN  (None, 281, 32)     128         ['conv1d_38[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_33 (LeakyReLU)     (None, 281, 32)      0           ['batch_normalization_33[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_39 (Conv1D)             (None, 281, 32)      3104        ['leaky_re_lu_33[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_34 (BatchN  (None, 281, 32)     128         ['conv1d_39[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_15 (Add)                   (None, 281, 32)      0           ['dropout_14[0][0]',             \n",
            "                                                                  'batch_normalization_34[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_34 (LeakyReLU)     (None, 281, 32)      0           ['add_15[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_15 (MaxPooling1D  (None, 140, 32)     0           ['leaky_re_lu_34[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_15 (Dropout)           (None, 140, 32)      0           ['max_pooling1d_15[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_40 (Conv1D)             (None, 70, 64)       6208        ['dropout_15[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_35 (BatchN  (None, 70, 64)      256         ['conv1d_40[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_35 (LeakyReLU)     (None, 70, 64)       0           ['batch_normalization_35[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_41 (Conv1D)             (None, 70, 64)       12352       ['leaky_re_lu_35[0][0]']         \n",
            "                                                                                                  \n",
            " conv1d_42 (Conv1D)             (None, 70, 64)       2112        ['dropout_15[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_36 (BatchN  (None, 70, 64)      256         ['conv1d_41[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_16 (Add)                   (None, 70, 64)       0           ['conv1d_42[0][0]',              \n",
            "                                                                  'batch_normalization_36[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_36 (LeakyReLU)     (None, 70, 64)       0           ['add_16[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_16 (MaxPooling1D  (None, 35, 64)      0           ['leaky_re_lu_36[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_16 (Dropout)           (None, 35, 64)       0           ['max_pooling1d_16[0][0]']       \n",
            "                                                                                                  \n",
            " conv1d_43 (Conv1D)             (None, 35, 64)       12352       ['dropout_16[0][0]']             \n",
            "                                                                                                  \n",
            " batch_normalization_37 (BatchN  (None, 35, 64)      256         ['conv1d_43[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_37 (LeakyReLU)     (None, 35, 64)       0           ['batch_normalization_37[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_44 (Conv1D)             (None, 35, 64)       12352       ['leaky_re_lu_37[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_38 (BatchN  (None, 35, 64)      256         ['conv1d_44[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_17 (Add)                   (None, 35, 64)       0           ['dropout_16[0][0]',             \n",
            "                                                                  'batch_normalization_38[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_38 (LeakyReLU)     (None, 35, 64)       0           ['add_17[0][0]']                 \n",
            "                                                                                                  \n",
            " max_pooling1d_17 (MaxPooling1D  (None, 17, 64)      0           ['leaky_re_lu_38[0][0]']         \n",
            " )                                                                                                \n",
            "                                                                                                  \n",
            " dropout_17 (Dropout)           (None, 17, 64)       0           ['max_pooling1d_17[0][0]']       \n",
            "                                                                                                  \n",
            " flatten_2 (Flatten)            (None, 1088)         0           ['dropout_17[0][0]']             \n",
            "                                                                                                  \n",
            " dense_2 (Dense)                (None, 2)            2178        ['flatten_2[0][0]']              \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 64,562\n",
            "Trainable params: 63,634\n",
            "Non-trainable params: 928\n",
            "__________________________________________________________________________________________________\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 0 ...\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.4459 - accuracy: 0.9031Result for validatin set - epoch: 0 - score: 0.586143\n",
            "\n",
            "Epoch 1: saving model to IK0_10_5_1.h5\n",
            "Testing Auc: 0.44552669552669555\n",
            "10/10 [==============================] - 18s 1s/step - loss: 1.4459 - accuracy: 0.9031 - val_loss: 32.6712 - val_accuracy: 0.0750 - lr: 0.0010 - val_auc: 0.5861\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.9140 - accuracy: 0.8906Result for validatin set - epoch: 1 - score: 0.393914\n",
            "\n",
            "Epoch 2: saving model to IK0_10_5_2.h5\n",
            "Testing Auc: 0.3946608946608947\n",
            "10/10 [==============================] - 15s 2s/step - loss: 0.9140 - accuracy: 0.8906 - val_loss: 1.2810 - val_accuracy: 0.9500 - lr: 0.0010 - val_auc: 0.3939\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.9094 - accuracy: 0.8969Result for validatin set - epoch: 2 - score: 0.487459\n",
            "\n",
            "Epoch 3: saving model to IK0_10_5_3.h5\n",
            "Testing Auc: 0.3662818662818663\n",
            "10/10 [==============================] - 16s 2s/step - loss: 0.9094 - accuracy: 0.8969 - val_loss: 0.7428 - val_accuracy: 0.8375 - lr: 0.0010 - val_auc: 0.4875\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6791 - accuracy: 0.9125Result for validatin set - epoch: 3 - score: 0.647204\n",
            "\n",
            "Epoch 4: saving model to IK0_10_5_4.h5\n",
            "Testing Auc: 0.3342953342953343\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.6791 - accuracy: 0.9125 - val_loss: 1.7524 - val_accuracy: 0.6000 - lr: 0.0010 - val_auc: 0.6472\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6093 - accuracy: 0.9172Result for validatin set - epoch: 4 - score: 0.587171\n",
            "\n",
            "Epoch 5: saving model to IK0_10_5_5.h5\n",
            "Testing Auc: 0.38864838864838863\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.6093 - accuracy: 0.9172 - val_loss: 0.9576 - val_accuracy: 0.7000 - lr: 0.0010 - val_auc: 0.5872\n",
            "------------------------------------------------------------------------\n",
            "CSV for 0 Saved...\n",
            "INFO:tensorflow:Assets written to: ram://91c184f8-893b-4245-99a2-4f1485bb9189/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://91c184f8-893b-4245-99a2-4f1485bb9189/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 0 Saved...\n",
            "ROC AUC score holdout:0.38864838864838863\n",
            "ROC AUC score validation:0.587171052631579\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 4500, 12)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 4500, 16)     592         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 4500, 16)    64          ['conv1d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 4500, 16)     0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 4500, 16)     784         ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 4500, 16)    64          ['conv1d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 4500, 16)     0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 4500, 16)     784         ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 4500, 16)    64          ['conv1d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 4500, 16)     0           ['leaky_re_lu[0][0]',            \n",
            "                                                                  'batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 4500, 16)     0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 2250, 16)     0           ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2250, 16)     0           ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 2250, 16)     784         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 2250, 16)    64          ['conv1d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 2250, 16)     0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 2250, 16)     784         ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 2250, 16)    64          ['conv1d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 2250, 16)     0           ['dropout[0][0]',                \n",
            "                                                                  'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 2250, 16)     0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 1125, 16)    0           ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 1125, 16)     0           ['max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 563, 32)      1568        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 563, 32)     128         ['conv1d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 563, 32)      0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 563, 32)      3104        ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 563, 32)      544         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 563, 32)     128         ['conv1d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 563, 32)      0           ['conv1d_7[0][0]',               \n",
            "                                                                  'batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 563, 32)      0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_2 (MaxPooling1D)  (None, 281, 32)     0           ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 281, 32)      0           ['max_pooling1d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 281, 32)      3104        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 281, 32)     128         ['conv1d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 281, 32)      0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 281, 32)      3104        ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 281, 32)     128         ['conv1d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 281, 32)      0           ['dropout_2[0][0]',              \n",
            "                                                                  'batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 281, 32)      0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_3 (MaxPooling1D)  (None, 140, 32)     0           ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 140, 32)      0           ['max_pooling1d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 70, 64)       6208        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 70, 64)      256         ['conv1d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 70, 64)       0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 70, 64)       12352       ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 70, 64)       2112        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 70, 64)      256         ['conv1d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 70, 64)       0           ['conv1d_12[0][0]',              \n",
            "                                                                  'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 70, 64)       0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_4 (MaxPooling1D)  (None, 35, 64)      0           ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 35, 64)       0           ['max_pooling1d_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 35, 64)       12352       ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 35, 64)      256         ['conv1d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 35, 64)       0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 35, 64)       12352       ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 35, 64)      256         ['conv1d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 35, 64)       0           ['dropout_4[0][0]',              \n",
            "                                                                  'batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_12 (LeakyReLU)     (None, 35, 64)       0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_5 (MaxPooling1D)  (None, 17, 64)      0           ['leaky_re_lu_12[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 17, 64)       0           ['max_pooling1d_5[0][0]']        \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 1088)         0           ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2)            2178        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 64,562\n",
            "Trainable params: 63,634\n",
            "Non-trainable params: 928\n",
            "__________________________________________________________________________________________________\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 1 ...\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.1967 - accuracy: 0.9156Result for validatin set - epoch: 0 - score: 0.544518\n",
            "\n",
            "Epoch 1: saving model to IK1_10_5_1.h5\n",
            "Testing Auc: 0.6277056277056277\n",
            "10/10 [==============================] - 19s 1s/step - loss: 1.1967 - accuracy: 0.9156 - val_loss: 32.8028 - val_accuracy: 0.0562 - lr: 0.0010 - val_auc: 0.5445\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.9109 - accuracy: 0.8938Result for validatin set - epoch: 1 - score: 0.654709\n",
            "\n",
            "Epoch 2: saving model to IK1_10_5_2.h5\n",
            "Testing Auc: 0.5733525733525733\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.9109 - accuracy: 0.8938 - val_loss: 2.5065 - val_accuracy: 0.5938 - lr: 0.0010 - val_auc: 0.6547\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7005 - accuracy: 0.9031Result for validatin set - epoch: 2 - score: 0.615894\n",
            "\n",
            "Epoch 3: saving model to IK1_10_5_3.h5\n",
            "Testing Auc: 0.6349206349206349\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.7005 - accuracy: 0.9031 - val_loss: 0.6256 - val_accuracy: 0.8938 - lr: 0.0010 - val_auc: 0.6159\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.8984 - accuracy: 0.9234Result for validatin set - epoch: 3 - score: 0.638705\n",
            "\n",
            "Epoch 4: saving model to IK1_10_5_4.h5\n",
            "Testing Auc: 0.7215007215007214\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.8984 - accuracy: 0.9234 - val_loss: 1.3357 - val_accuracy: 0.6687 - lr: 0.0010 - val_auc: 0.6387\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7402 - accuracy: 0.9094Result for validatin set - epoch: 4 - score: 0.564937\n",
            "\n",
            "Epoch 5: saving model to IK1_10_5_5.h5\n",
            "Testing Auc: 0.6352813852813852\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.7402 - accuracy: 0.9094 - val_loss: 0.5772 - val_accuracy: 0.9312 - lr: 0.0010 - val_auc: 0.5649\n",
            "------------------------------------------------------------------------\n",
            "CSV for 1 Saved...\n",
            "INFO:tensorflow:Assets written to: ram://d2e6884f-7d38-45ce-8729-bfe6766fdd9b/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://d2e6884f-7d38-45ce-8729-bfe6766fdd9b/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 1 Saved...\n",
            "ROC AUC score holdout:0.6354016354016354\n",
            "ROC AUC score validation:0.565121412803532\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 4500, 12)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 4500, 16)     592         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 4500, 16)    64          ['conv1d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 4500, 16)     0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 4500, 16)     784         ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 4500, 16)    64          ['conv1d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 4500, 16)     0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 4500, 16)     784         ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 4500, 16)    64          ['conv1d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 4500, 16)     0           ['leaky_re_lu[0][0]',            \n",
            "                                                                  'batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 4500, 16)     0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 2250, 16)     0           ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2250, 16)     0           ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 2250, 16)     784         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 2250, 16)    64          ['conv1d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 2250, 16)     0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 2250, 16)     784         ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 2250, 16)    64          ['conv1d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 2250, 16)     0           ['dropout[0][0]',                \n",
            "                                                                  'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 2250, 16)     0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 1125, 16)    0           ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 1125, 16)     0           ['max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 563, 32)      1568        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 563, 32)     128         ['conv1d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 563, 32)      0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 563, 32)      3104        ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 563, 32)      544         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 563, 32)     128         ['conv1d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 563, 32)      0           ['conv1d_7[0][0]',               \n",
            "                                                                  'batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 563, 32)      0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_2 (MaxPooling1D)  (None, 281, 32)     0           ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 281, 32)      0           ['max_pooling1d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 281, 32)      3104        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 281, 32)     128         ['conv1d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 281, 32)      0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 281, 32)      3104        ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 281, 32)     128         ['conv1d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 281, 32)      0           ['dropout_2[0][0]',              \n",
            "                                                                  'batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 281, 32)      0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_3 (MaxPooling1D)  (None, 140, 32)     0           ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 140, 32)      0           ['max_pooling1d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 70, 64)       6208        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 70, 64)      256         ['conv1d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 70, 64)       0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 70, 64)       12352       ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 70, 64)       2112        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 70, 64)      256         ['conv1d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 70, 64)       0           ['conv1d_12[0][0]',              \n",
            "                                                                  'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 70, 64)       0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_4 (MaxPooling1D)  (None, 35, 64)      0           ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 35, 64)       0           ['max_pooling1d_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 35, 64)       12352       ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 35, 64)      256         ['conv1d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 35, 64)       0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 35, 64)       12352       ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 35, 64)      256         ['conv1d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 35, 64)       0           ['dropout_4[0][0]',              \n",
            "                                                                  'batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_12 (LeakyReLU)     (None, 35, 64)       0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_5 (MaxPooling1D)  (None, 17, 64)      0           ['leaky_re_lu_12[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 17, 64)       0           ['max_pooling1d_5[0][0]']        \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 1088)         0           ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2)            2178        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 64,562\n",
            "Trainable params: 63,634\n",
            "Non-trainable params: 928\n",
            "__________________________________________________________________________________________________\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 2 ...\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 2.4517 - accuracy: 0.8125Result for validatin set - epoch: 0 - score: 0.500000\n",
            "\n",
            "Epoch 1: saving model to IK2_10_5_1.h5\n",
            "Testing Auc: 0.5\n",
            "10/10 [==============================] - 19s 1s/step - loss: 2.4517 - accuracy: 0.8125 - val_loss: 18.1016 - val_accuracy: 0.9438 - lr: 0.0010 - val_auc: 0.5000\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.9474 - accuracy: 0.9453Result for validatin set - epoch: 1 - score: 0.364790\n",
            "\n",
            "Epoch 2: saving model to IK2_10_5_2.h5\n",
            "Testing Auc: 0.43999518999519005\n",
            "10/10 [==============================] - 12s 1s/step - loss: 1.9474 - accuracy: 0.9453 - val_loss: 6.4302 - val_accuracy: 0.9438 - lr: 0.0010 - val_auc: 0.3648\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.2947 - accuracy: 0.9453Result for validatin set - epoch: 2 - score: 0.415931\n",
            "\n",
            "Epoch 3: saving model to IK2_10_5_3.h5\n",
            "Testing Auc: 0.25757575757575757\n",
            "10/10 [==============================] - 13s 1s/step - loss: 1.2947 - accuracy: 0.9453 - val_loss: 1.1646 - val_accuracy: 0.8813 - lr: 0.0010 - val_auc: 0.4159\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6953 - accuracy: 0.8859Result for validatin set - epoch: 3 - score: 0.309235\n",
            "\n",
            "Epoch 4: saving model to IK2_10_5_4.h5\n",
            "Testing Auc: 0.3209475709475709\n",
            "10/10 [==============================] - 14s 1s/step - loss: 0.6953 - accuracy: 0.8859 - val_loss: 0.9234 - val_accuracy: 0.9312 - lr: 0.0010 - val_auc: 0.3092\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5504 - accuracy: 0.9344Result for validatin set - epoch: 4 - score: 0.322848\n",
            "\n",
            "Epoch 5: saving model to IK2_10_5_5.h5\n",
            "Testing Auc: 0.38840788840788837\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.5504 - accuracy: 0.9344 - val_loss: 0.9012 - val_accuracy: 0.9438 - lr: 0.0010 - val_auc: 0.3228\n",
            "------------------------------------------------------------------------\n",
            "CSV for 2 Saved...\n",
            "INFO:tensorflow:Assets written to: ram://77435d99-310c-4212-957f-44dfc1ba0d37/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://77435d99-310c-4212-957f-44dfc1ba0d37/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 2 Saved...\n",
            "ROC AUC score holdout:0.38768638768638763\n",
            "ROC AUC score validation:0.3222958057395144\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 4500, 12)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 4500, 16)     592         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 4500, 16)    64          ['conv1d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 4500, 16)     0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 4500, 16)     784         ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 4500, 16)    64          ['conv1d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 4500, 16)     0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 4500, 16)     784         ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 4500, 16)    64          ['conv1d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 4500, 16)     0           ['leaky_re_lu[0][0]',            \n",
            "                                                                  'batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 4500, 16)     0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 2250, 16)     0           ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2250, 16)     0           ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 2250, 16)     784         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 2250, 16)    64          ['conv1d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 2250, 16)     0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 2250, 16)     784         ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 2250, 16)    64          ['conv1d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 2250, 16)     0           ['dropout[0][0]',                \n",
            "                                                                  'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 2250, 16)     0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 1125, 16)    0           ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 1125, 16)     0           ['max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 563, 32)      1568        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 563, 32)     128         ['conv1d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 563, 32)      0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 563, 32)      3104        ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 563, 32)      544         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 563, 32)     128         ['conv1d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 563, 32)      0           ['conv1d_7[0][0]',               \n",
            "                                                                  'batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 563, 32)      0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_2 (MaxPooling1D)  (None, 281, 32)     0           ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 281, 32)      0           ['max_pooling1d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 281, 32)      3104        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 281, 32)     128         ['conv1d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 281, 32)      0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 281, 32)      3104        ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 281, 32)     128         ['conv1d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 281, 32)      0           ['dropout_2[0][0]',              \n",
            "                                                                  'batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 281, 32)      0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_3 (MaxPooling1D)  (None, 140, 32)     0           ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 140, 32)      0           ['max_pooling1d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 70, 64)       6208        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 70, 64)      256         ['conv1d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 70, 64)       0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 70, 64)       12352       ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 70, 64)       2112        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 70, 64)      256         ['conv1d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 70, 64)       0           ['conv1d_12[0][0]',              \n",
            "                                                                  'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 70, 64)       0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_4 (MaxPooling1D)  (None, 35, 64)      0           ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 35, 64)       0           ['max_pooling1d_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 35, 64)       12352       ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 35, 64)      256         ['conv1d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 35, 64)       0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 35, 64)       12352       ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 35, 64)      256         ['conv1d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 35, 64)       0           ['dropout_4[0][0]',              \n",
            "                                                                  'batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_12 (LeakyReLU)     (None, 35, 64)       0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_5 (MaxPooling1D)  (None, 17, 64)      0           ['leaky_re_lu_12[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 17, 64)       0           ['max_pooling1d_5[0][0]']        \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 1088)         0           ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2)            2178        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 64,562\n",
            "Trainable params: 63,634\n",
            "Non-trainable params: 928\n",
            "__________________________________________________________________________________________________\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 3 ...\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 2.1184 - accuracy: 0.9016Result for validatin set - epoch: 0 - score: 0.461185\n",
            "\n",
            "Epoch 1: saving model to IK3_10_5_1.h5\n",
            "Testing Auc: 0.48304473304473305\n",
            "10/10 [==============================] - 19s 1s/step - loss: 2.1184 - accuracy: 0.9016 - val_loss: 3.6625 - val_accuracy: 0.9438 - lr: 0.0010 - val_auc: 0.4612\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.5616 - accuracy: 0.8594Result for validatin set - epoch: 1 - score: 0.410596\n",
            "\n",
            "Epoch 2: saving model to IK3_10_5_2.h5\n",
            "Testing Auc: 0.5901875901875901\n",
            "10/10 [==============================] - 13s 1s/step - loss: 1.5616 - accuracy: 0.8594 - val_loss: 3.3616 - val_accuracy: 0.5875 - lr: 0.0010 - val_auc: 0.4106\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.1504 - accuracy: 0.9453Result for validatin set - epoch: 2 - score: 0.389625\n",
            "\n",
            "Epoch 3: saving model to IK3_10_5_3.h5\n",
            "Testing Auc: 0.5328282828282829\n",
            "10/10 [==============================] - 13s 1s/step - loss: 1.1504 - accuracy: 0.9453 - val_loss: 1.1954 - val_accuracy: 0.9375 - lr: 0.0010 - val_auc: 0.3896\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.9624 - accuracy: 0.9078Result for validatin set - epoch: 3 - score: 0.431935\n",
            "\n",
            "Epoch 4: saving model to IK3_10_5_4.h5\n",
            "Testing Auc: 0.5916305916305917\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.9624 - accuracy: 0.9078 - val_loss: 1.8329 - val_accuracy: 0.6250 - lr: 0.0010 - val_auc: 0.4319\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.7141 - accuracy: 0.9203Result for validatin set - epoch: 4 - score: 0.372884\n",
            "\n",
            "Epoch 5: saving model to IK3_10_5_5.h5\n",
            "Testing Auc: 0.5478595478595478\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.7141 - accuracy: 0.9203 - val_loss: 0.7379 - val_accuracy: 0.9062 - lr: 0.0010 - val_auc: 0.3729\n",
            "------------------------------------------------------------------------\n",
            "CSV for 3 Saved...\n",
            "INFO:tensorflow:Assets written to: ram://54838ec7-9850-442a-aed9-2b28fff92d72/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://54838ec7-9850-442a-aed9-2b28fff92d72/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 3 Saved...\n",
            "ROC AUC score holdout:0.5478595478595478\n",
            "ROC AUC score validation:0.3730684326710817\n",
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "WARNING:tensorflow:`period` argument is deprecated. Please use `save_freq` to specify the frequency in number of batches seen.\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"model\"\n",
            "__________________________________________________________________________________________________\n",
            " Layer (type)                   Output Shape         Param #     Connected to                     \n",
            "==================================================================================================\n",
            " input_1 (InputLayer)           [(None, 4500, 12)]   0           []                               \n",
            "                                                                                                  \n",
            " conv1d (Conv1D)                (None, 4500, 16)     592         ['input_1[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization (BatchNorm  (None, 4500, 16)    64          ['conv1d[0][0]']                 \n",
            " alization)                                                                                       \n",
            "                                                                                                  \n",
            " leaky_re_lu (LeakyReLU)        (None, 4500, 16)     0           ['batch_normalization[0][0]']    \n",
            "                                                                                                  \n",
            " conv1d_1 (Conv1D)              (None, 4500, 16)     784         ['leaky_re_lu[0][0]']            \n",
            "                                                                                                  \n",
            " batch_normalization_1 (BatchNo  (None, 4500, 16)    64          ['conv1d_1[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_1 (LeakyReLU)      (None, 4500, 16)     0           ['batch_normalization_1[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_2 (Conv1D)              (None, 4500, 16)     784         ['leaky_re_lu_1[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_2 (BatchNo  (None, 4500, 16)    64          ['conv1d_2[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add (Add)                      (None, 4500, 16)     0           ['leaky_re_lu[0][0]',            \n",
            "                                                                  'batch_normalization_2[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_2 (LeakyReLU)      (None, 4500, 16)     0           ['add[0][0]']                    \n",
            "                                                                                                  \n",
            " max_pooling1d (MaxPooling1D)   (None, 2250, 16)     0           ['leaky_re_lu_2[0][0]']          \n",
            "                                                                                                  \n",
            " dropout (Dropout)              (None, 2250, 16)     0           ['max_pooling1d[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_3 (Conv1D)              (None, 2250, 16)     784         ['dropout[0][0]']                \n",
            "                                                                                                  \n",
            " batch_normalization_3 (BatchNo  (None, 2250, 16)    64          ['conv1d_3[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_3 (LeakyReLU)      (None, 2250, 16)     0           ['batch_normalization_3[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_4 (Conv1D)              (None, 2250, 16)     784         ['leaky_re_lu_3[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_4 (BatchNo  (None, 2250, 16)    64          ['conv1d_4[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_1 (Add)                    (None, 2250, 16)     0           ['dropout[0][0]',                \n",
            "                                                                  'batch_normalization_4[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_4 (LeakyReLU)      (None, 2250, 16)     0           ['add_1[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_1 (MaxPooling1D)  (None, 1125, 16)    0           ['leaky_re_lu_4[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_1 (Dropout)            (None, 1125, 16)     0           ['max_pooling1d_1[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_5 (Conv1D)              (None, 563, 32)      1568        ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_5 (BatchNo  (None, 563, 32)     128         ['conv1d_5[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_5 (LeakyReLU)      (None, 563, 32)      0           ['batch_normalization_5[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_6 (Conv1D)              (None, 563, 32)      3104        ['leaky_re_lu_5[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_7 (Conv1D)              (None, 563, 32)      544         ['dropout_1[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_6 (BatchNo  (None, 563, 32)     128         ['conv1d_6[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_2 (Add)                    (None, 563, 32)      0           ['conv1d_7[0][0]',               \n",
            "                                                                  'batch_normalization_6[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_6 (LeakyReLU)      (None, 563, 32)      0           ['add_2[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_2 (MaxPooling1D)  (None, 281, 32)     0           ['leaky_re_lu_6[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_2 (Dropout)            (None, 281, 32)      0           ['max_pooling1d_2[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_8 (Conv1D)              (None, 281, 32)      3104        ['dropout_2[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_7 (BatchNo  (None, 281, 32)     128         ['conv1d_8[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_7 (LeakyReLU)      (None, 281, 32)      0           ['batch_normalization_7[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_9 (Conv1D)              (None, 281, 32)      3104        ['leaky_re_lu_7[0][0]']          \n",
            "                                                                                                  \n",
            " batch_normalization_8 (BatchNo  (None, 281, 32)     128         ['conv1d_9[0][0]']               \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " add_3 (Add)                    (None, 281, 32)      0           ['dropout_2[0][0]',              \n",
            "                                                                  'batch_normalization_8[0][0]']  \n",
            "                                                                                                  \n",
            " leaky_re_lu_8 (LeakyReLU)      (None, 281, 32)      0           ['add_3[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_3 (MaxPooling1D)  (None, 140, 32)     0           ['leaky_re_lu_8[0][0]']          \n",
            "                                                                                                  \n",
            " dropout_3 (Dropout)            (None, 140, 32)      0           ['max_pooling1d_3[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_10 (Conv1D)             (None, 70, 64)       6208        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_9 (BatchNo  (None, 70, 64)      256         ['conv1d_10[0][0]']              \n",
            " rmalization)                                                                                     \n",
            "                                                                                                  \n",
            " leaky_re_lu_9 (LeakyReLU)      (None, 70, 64)       0           ['batch_normalization_9[0][0]']  \n",
            "                                                                                                  \n",
            " conv1d_11 (Conv1D)             (None, 70, 64)       12352       ['leaky_re_lu_9[0][0]']          \n",
            "                                                                                                  \n",
            " conv1d_12 (Conv1D)             (None, 70, 64)       2112        ['dropout_3[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_10 (BatchN  (None, 70, 64)      256         ['conv1d_11[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_4 (Add)                    (None, 70, 64)       0           ['conv1d_12[0][0]',              \n",
            "                                                                  'batch_normalization_10[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_10 (LeakyReLU)     (None, 70, 64)       0           ['add_4[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_4 (MaxPooling1D)  (None, 35, 64)      0           ['leaky_re_lu_10[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_4 (Dropout)            (None, 35, 64)       0           ['max_pooling1d_4[0][0]']        \n",
            "                                                                                                  \n",
            " conv1d_13 (Conv1D)             (None, 35, 64)       12352       ['dropout_4[0][0]']              \n",
            "                                                                                                  \n",
            " batch_normalization_11 (BatchN  (None, 35, 64)      256         ['conv1d_13[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " leaky_re_lu_11 (LeakyReLU)     (None, 35, 64)       0           ['batch_normalization_11[0][0]'] \n",
            "                                                                                                  \n",
            " conv1d_14 (Conv1D)             (None, 35, 64)       12352       ['leaky_re_lu_11[0][0]']         \n",
            "                                                                                                  \n",
            " batch_normalization_12 (BatchN  (None, 35, 64)      256         ['conv1d_14[0][0]']              \n",
            " ormalization)                                                                                    \n",
            "                                                                                                  \n",
            " add_5 (Add)                    (None, 35, 64)       0           ['dropout_4[0][0]',              \n",
            "                                                                  'batch_normalization_12[0][0]'] \n",
            "                                                                                                  \n",
            " leaky_re_lu_12 (LeakyReLU)     (None, 35, 64)       0           ['add_5[0][0]']                  \n",
            "                                                                                                  \n",
            " max_pooling1d_5 (MaxPooling1D)  (None, 17, 64)      0           ['leaky_re_lu_12[0][0]']         \n",
            "                                                                                                  \n",
            " dropout_5 (Dropout)            (None, 17, 64)       0           ['max_pooling1d_5[0][0]']        \n",
            "                                                                                                  \n",
            " flatten (Flatten)              (None, 1088)         0           ['dropout_5[0][0]']              \n",
            "                                                                                                  \n",
            " dense (Dense)                  (None, 2)            2178        ['flatten[0][0]']                \n",
            "                                                                                                  \n",
            "==================================================================================================\n",
            "Total params: 64,562\n",
            "Trainable params: 63,634\n",
            "Non-trainable params: 928\n",
            "__________________________________________________________________________________________________\n",
            "------------------------------------------------------------------------\n",
            "Training for fold 4 ...\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 1: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 1/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 1.0880 - accuracy: 0.8922Result for validatin set - epoch: 0 - score: 0.470199\n",
            "\n",
            "Epoch 1: saving model to IK4_10_5_1.h5\n",
            "Testing Auc: 0.3345358345358346\n",
            "10/10 [==============================] - 18s 1s/step - loss: 1.0880 - accuracy: 0.8922 - val_loss: 7.3118 - val_accuracy: 0.6687 - lr: 0.0010 - val_auc: 0.4702\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 2: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 2/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.8194 - accuracy: 0.9141Result for validatin set - epoch: 1 - score: 0.445916\n",
            "\n",
            "Epoch 2: saving model to IK4_10_5_2.h5\n",
            "Testing Auc: 0.30567580567580566\n",
            "10/10 [==============================] - 13s 1s/step - loss: 0.8194 - accuracy: 0.9141 - val_loss: 5.0959 - val_accuracy: 0.6187 - lr: 0.0010 - val_auc: 0.4459\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 3: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 3/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.8391 - accuracy: 0.9125Result for validatin set - epoch: 2 - score: 0.572480\n",
            "\n",
            "Epoch 3: saving model to IK4_10_5_3.h5\n",
            "Testing Auc: 0.38083213083213086\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.8391 - accuracy: 0.9125 - val_loss: 1.2873 - val_accuracy: 0.9438 - lr: 0.0010 - val_auc: 0.5725\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 4: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 4/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.5255 - accuracy: 0.9141Result for validatin set - epoch: 3 - score: 0.595475\n",
            "\n",
            "Epoch 4: saving model to IK4_10_5_4.h5\n",
            "Testing Auc: 0.42953342953342954\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.5255 - accuracy: 0.9141 - val_loss: 0.7300 - val_accuracy: 0.9438 - lr: 0.0010 - val_auc: 0.5955\n",
            "Learning rate:  0.0010000000474974513\n",
            "\n",
            "Epoch 5: LearningRateScheduler setting learning rate to 0.0010000000474974513.\n",
            "Epoch 5/5\n",
            "10/10 [==============================] - ETA: 0s - loss: 0.6583 - accuracy: 0.9219Result for validatin set - epoch: 4 - score: 0.575423\n",
            "\n",
            "Epoch 5: saving model to IK4_10_5_5.h5\n",
            "Testing Auc: 0.41366041366041373\n",
            "10/10 [==============================] - 12s 1s/step - loss: 0.6583 - accuracy: 0.9219 - val_loss: 0.7290 - val_accuracy: 0.9187 - lr: 0.0010 - val_auc: 0.5754\n",
            "------------------------------------------------------------------------\n",
            "CSV for 4 Saved...\n",
            "INFO:tensorflow:Assets written to: ram://9e52f83b-39b5-4fa7-8f76-a71e8f67f308/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "INFO:tensorflow:Assets written to: ram://9e52f83b-39b5-4fa7-8f76-a71e8f67f308/assets\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model 4 Saved...\n",
            "ROC AUC score holdout:0.41462241462241467\n",
            "ROC AUC score validation:0.5754231052244297\n"
          ]
        }
      ],
      "source": [
        "\n",
        "xhist=[]\n",
        "\n",
        "\n",
        "x_test = X_holdout\n",
        "y_test = np_utils.to_categorical(y_holdout , num_classes=2) # One-hot encoding\n",
        "    \n",
        "\n",
        "    \n",
        "for i in range(5):\n",
        "\n",
        "    fold_no = i\n",
        "    \n",
        "    x_train = TRA_X[i]\n",
        "    y_train = np_utils.to_categorical(TRA_Y[i] , num_classes=2)\n",
        "    \n",
        "    x_val = VAL_X[i]\n",
        "    y_val = np_utils.to_categorical(VAL_Y[i] , num_classes=2)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # adam = Adam(lr = 0.001, beta_1 = 0.9, beta_2 = 0.999, clipnorm=1)\n",
        "    my_callbacks = EarlyStopping(monitor='val_auc', patience=5, restore_best_weights = True, verbose=1, mode='max')\n",
        "    checkpoint = keras.callbacks.ModelCheckpoint('IK' +str(i) +'_10_5_{epoch:d}.h5', period=1, mode = 'min', verbose = 1, \n",
        "                                                 save_best_only = False) \n",
        "    \n",
        "    callbacksx =  keras.callbacks.LearningRateScheduler(lr_scheduler, verbose=1)\n",
        "    \n",
        "    reduce_lr=ReduceLROnPlateau(monitor='auc_roc',factor=0.2,patience=5,min_lr=0.0001)\n",
        "    my_callbacks = val_auc(validation_data=(x_val, y_val), interval=1)\n",
        "    \n",
        "    \n",
        "    \n",
        "    # Define the model architecture\n",
        "    model = resnet_v1(input_shape=input_shape, depth=depth)\n",
        "    \n",
        "    \n",
        "\n",
        "    # Generate a print\n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'Training for fold {fold_no} ...')\n",
        "    \n",
        "\n",
        "    #class_weight = {0: 1.,1: 2.}\n",
        "   \n",
        "    model.compile(loss='categorical_crossentropy',optimizer=\"adam\",metrics=['accuracy'])\n",
        "    \n",
        "    \n",
        "    \n",
        "    history = model.fit(x_train, y_train, epochs=epoch,\n",
        "                        batch_size=batch_size, \n",
        "                        callbacks=[callbacksx, my_callbacks, checkpoint, TestCallback((x_test, y_test))],\n",
        "                        validation_data=(x_val, y_val))\n",
        "    \n",
        "    xhist.append(history)\n",
        "    \n",
        "\n",
        "    predict = model.predict(x_test)\n",
        "    prediction_binary = np.where(predict[:,1] > 0.5, 1, 0)\n",
        "    \n",
        "    \n",
        "    ytest_df = pd.DataFrame(y_test[:,1])\n",
        "    predict_df = pd.DataFrame(predict[:,1])\n",
        "    \n",
        "    output = pd.concat([ ytest_df, predict_df], axis = 1).set_index(Feat_holdout.index)\n",
        "    \n",
        "    output.columns = ['y_true', 'predicted']\n",
        "    #output['ID'] = Feat_holdout['ID']\n",
        "    output.to_csv(f'Holdout_pred_for_Fold{fold_no}.csv')\n",
        "    \n",
        "    \n",
        "    \n",
        "    print('------------------------------------------------------------------------')\n",
        "    print(f'CSV for {fold_no} Saved...')\n",
        "\n",
        "    predict_val = model.predict(x_val)\n",
        "    \n",
        "    \n",
        "    val_df = pd.DataFrame(y_val[:,1])\n",
        "    predict_val_df = pd.DataFrame(predict_val[:,1])\n",
        "\n",
        "    \n",
        "    output_val = pd.concat([ val_df, predict_val_df], axis = 1).set_index(feat_VAL_X[fold_no].index)\n",
        "    \n",
        "    output_val.columns = ['valy_true', 'predict_validation']\n",
        "    #output_val['ID'] = feat_VAL_X[fold_no]['ID']\n",
        "    output_val.to_csv(f'Validation_pred_for_Fold{fold_no}.csv')\n",
        "    \n",
        "\n",
        "    joblib.dump(history, f'IK_TrainSplit_{fold_no}.pkl')\n",
        "    print(f'Model {fold_no} Saved...')\n",
        "    \n",
        "    # Generate generalization metrics\n",
        "    scores_1 = roc_auc_score(y_test[:,1], predict[:,1])\n",
        "    print('ROC AUC score holdout:{}'.format(scores_1))\n",
        "    acc_per_fold.append(scores_1 * 100)\n",
        "    \n",
        "    scores_2 = roc_auc_score(y_val[:,1], predict_val[:,1])\n",
        "    print('ROC AUC score validation:{}'.format(scores_2))\n",
        "    acc_val_per_fold.append(scores_2 * 100) \n",
        "    \n",
        "    K.clear_session()\n",
        "    \n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "79b3674c",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "79b3674c",
        "outputId": "7bbb1a4e-8666-4e7a-98f2-5636c9dfdfce"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "3 0.647203947368421\n",
            "1 0.6547093451066961\n",
            "0 0.5\n",
            "0 0.4611846946284032\n",
            "3 0.5954746136865342\n"
          ]
        }
      ],
      "source": [
        "\n",
        "for i in range(5):\n",
        "    print (np.argmax(xhist[i].history['val_auc']), np.max(xhist[i].history['val_auc']))"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "acc_per_fold"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1XQ-uyo5hMV4",
        "outputId": "a283ef04-10a5-43b7-f7c8-d1546f1f6d7b"
      },
      "id": "1XQ-uyo5hMV4",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[38.864838864838866,\n",
              " 63.54016354016354,\n",
              " 38.768638768638766,\n",
              " 54.785954785954786,\n",
              " 41.462241462241465]"
            ]
          },
          "metadata": {},
          "execution_count": 45
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature Extraction from saved model\n",
        "\n",
        "- The abstract representation of the input\n",
        "- You could consider that if you have a n-layers DNN classifier, the n−1 layers constitute a feature extractor. The last layer is a linear classifier that operate on these complex, task-specific, learned features.\n"
      ],
      "metadata": {
        "id": "0SPgN_bwiCal"
      },
      "id": "0SPgN_bwiCal"
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "import keras\n",
        "\n",
        "pipeline_estimator = joblib.load('IK_TrainSplit_0.pkl')\n",
        "model = keras.models.load_model('IK0_10_5_4.h5')"
      ],
      "metadata": {
        "id": "eztzr2EwhNO9"
      },
      "id": "eztzr2EwhNO9",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5ePJ7MpCjNNl",
        "outputId": "7a52b4d1-c7f4-4c90-9bb5-9e55f2093b93"
      },
      "id": "5ePJ7MpCjNNl",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<keras.engine.input_layer.InputLayer at 0x7f9de82f9e90>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7f9de6e7a6d0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f9de6e7abd0>,\n",
              " <keras.layers.advanced_activations.LeakyReLU at 0x7f9de810fc50>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7f9de810f650>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f9de82f8890>,\n",
              " <keras.layers.advanced_activations.LeakyReLU at 0x7f9de82f9990>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7f9de82f9790>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f9de4187750>,\n",
              " <keras.layers.merge.Add at 0x7f9de436d950>,\n",
              " <keras.layers.advanced_activations.LeakyReLU at 0x7f9de4192e90>,\n",
              " <keras.layers.pooling.MaxPooling1D at 0x7f9de4192090>,\n",
              " <keras.layers.core.dropout.Dropout at 0x7f9de4117550>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7f9de4117610>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f9de4187050>,\n",
              " <keras.layers.advanced_activations.LeakyReLU at 0x7f9de4117c10>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7f9de417d6d0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f9de417d850>,\n",
              " <keras.layers.merge.Add at 0x7f9de651f3d0>,\n",
              " <keras.layers.advanced_activations.LeakyReLU at 0x7f9de4129f50>,\n",
              " <keras.layers.pooling.MaxPooling1D at 0x7f9de4129590>,\n",
              " <keras.layers.core.dropout.Dropout at 0x7f9de4129890>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7f9de4129d90>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f9de41257d0>,\n",
              " <keras.layers.advanced_activations.LeakyReLU at 0x7f9de4125d90>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7f9de4125cd0>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7f9de4112150>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f9de4364350>,\n",
              " <keras.layers.merge.Add at 0x7f9de4364150>,\n",
              " <keras.layers.advanced_activations.LeakyReLU at 0x7f9de417de90>,\n",
              " <keras.layers.pooling.MaxPooling1D at 0x7f9de7add3d0>,\n",
              " <keras.layers.core.dropout.Dropout at 0x7f9de43c5810>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7f9de43c5b50>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f9de4c03350>,\n",
              " <keras.layers.advanced_activations.LeakyReLU at 0x7f9de8293090>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7f9de076ffd0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f9de4c03ed0>,\n",
              " <keras.layers.merge.Add at 0x7f9de076ff10>,\n",
              " <keras.layers.advanced_activations.LeakyReLU at 0x7f9de7a42590>,\n",
              " <keras.layers.pooling.MaxPooling1D at 0x7f9de436d490>,\n",
              " <keras.layers.core.dropout.Dropout at 0x7f9de823d150>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7f9de07f41d0>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f9de07f4bd0>,\n",
              " <keras.layers.advanced_activations.LeakyReLU at 0x7f9de7cf6110>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7f9de3f816d0>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7f9de3f81f90>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f9de3f6bc10>,\n",
              " <keras.layers.merge.Add at 0x7f9de07f4690>,\n",
              " <keras.layers.advanced_activations.LeakyReLU at 0x7f9de6b378d0>,\n",
              " <keras.layers.pooling.MaxPooling1D at 0x7f9de3f70110>,\n",
              " <keras.layers.core.dropout.Dropout at 0x7f9de3f70b90>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7f9de2edc950>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f9de44c7990>,\n",
              " <keras.layers.advanced_activations.LeakyReLU at 0x7f9de6dd4410>,\n",
              " <keras.layers.convolutional.Conv1D at 0x7f9de3f47d10>,\n",
              " <keras.layers.normalization.batch_normalization.BatchNormalization at 0x7f9de6d019d0>,\n",
              " <keras.layers.merge.Add at 0x7f9de3eecc50>,\n",
              " <keras.layers.advanced_activations.LeakyReLU at 0x7f9de486d1d0>,\n",
              " <keras.layers.pooling.MaxPooling1D at 0x7f9de48be1d0>,\n",
              " <keras.layers.core.dropout.Dropout at 0x7f9de477aa90>,\n",
              " <keras.layers.core.flatten.Flatten at 0x7f9de80c6450>,\n",
              " <keras.layers.core.dense.Dense at 0x7f9de8f58550>]"
            ]
          },
          "metadata": {},
          "execution_count": 48
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "model.layers[-2]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HXz-46vck1E3",
        "outputId": "1dcba8c3-8a33-4d68-f034-329907c11f9f"
      },
      "id": "HXz-46vck1E3",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.layers.core.flatten.Flatten at 0x7f9de80c6450>"
            ]
          },
          "metadata": {},
          "execution_count": 51
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "layer_output=model.layers[-2].output\n",
        "layer_input1=model.layers[0].input\n",
        "intermediate_model= Model(inputs=layer_input1, outputs=layer_output)\n"
      ],
      "metadata": {
        "id": "F8BojtYkjIoH"
      },
      "id": "F8BojtYkjIoH",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_last_feat_fold0=pd.DataFrame(intermediate_model.predict([x_test]))\n",
        "X_test_last_feat_fold0"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 424
        },
        "id": "FbauHoXOjI22",
        "outputId": "287e9784-e22d-4a4f-a63b-031e820c1d09"
      },
      "id": "FbauHoXOjI22",
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "         0         1         2         3         4         5         6     \\\n",
              "0    0.719750  1.295104  0.270759 -0.012204  2.155092  0.476580 -0.052861   \n",
              "1    0.355583  6.395618  1.158820 -0.007579  0.325328  0.293184 -0.074968   \n",
              "2    0.524714  2.672114  1.196146  0.008120  0.461488  0.417234 -0.081589   \n",
              "3    1.274993  2.302675  2.919310  0.566198 -0.001330 -0.071372 -0.013177   \n",
              "4    3.056850  9.784783  4.041884  2.785742  0.694391  0.036745 -0.098161   \n",
              "..        ...       ...       ...       ...       ...       ...       ...   \n",
              "195  4.634676  8.718454  5.458107  0.836749  1.634265  0.159487 -0.107236   \n",
              "196  0.435286  5.644265  0.847490  0.064042  2.894183  0.580675 -0.056917   \n",
              "197  0.706380  0.995824  0.737084  3.865249 -0.027228  0.846497 -0.036266   \n",
              "198  0.124875  4.242362 -0.027758  2.369631 -0.142721  0.463358 -0.023451   \n",
              "199  0.263641  0.178472  1.683303 -0.011357  1.979308 -0.060579 -0.060716   \n",
              "\n",
              "          7          8         9     ...      1078      1079       1080  \\\n",
              "0     4.335659   3.820559  1.658292  ... -0.471146 -0.100195  17.739914   \n",
              "1    10.191537  10.701912  1.583432  ... -0.307946 -0.407126  13.410018   \n",
              "2     4.003283   3.449667  0.653876  ... -0.100608  2.089319   5.718911   \n",
              "3     5.449011  11.848956  1.035774  ... -0.130915 -0.077245  12.868748   \n",
              "4    16.720371  19.554396  4.057654  ... -0.865711 -0.096464  30.439096   \n",
              "..         ...        ...       ...  ...       ...       ...        ...   \n",
              "195  10.816562  19.774166  2.466617  ...  0.851185  6.701710   8.501316   \n",
              "196   9.097086   9.307425  1.399802  ... -0.465506 -0.132188  12.518223   \n",
              "197   4.954056   6.965610  0.592042  ... -0.196906  0.335270   9.476474   \n",
              "198   7.406272   5.642257  1.051440  ... -0.177335  1.014689  15.748517   \n",
              "199   3.535658   2.827784  1.168633  ... -0.593845 -0.038523  17.085106   \n",
              "\n",
              "          1081      1082      1083       1084      1085      1086      1087  \n",
              "0     4.319383  4.136518  3.483100  14.281128 -0.402702  7.009530  7.430326  \n",
              "1     9.353767  1.683759  9.184101   8.624210 -0.652683  5.231555  6.766066  \n",
              "2     4.863150  1.414717  0.968559   7.228348 -0.174857  1.096362  2.670488  \n",
              "3     8.057802  3.422311 -0.041648   4.870863 -0.154996  7.375211  2.683106  \n",
              "4     8.097186  2.357097  6.244454  24.742315 -0.975386  4.698389  9.966484  \n",
              "..         ...       ...       ...        ...       ...       ...       ...  \n",
              "195   7.520336 -0.094893  1.861775   9.154671 -0.453004 -0.034368  3.734820  \n",
              "196   7.247079  0.516293  5.981341   9.982636 -0.318908  4.652848  6.547028  \n",
              "197   1.476306  0.884588  1.249459  10.813810 -0.293770  4.201102  3.899903  \n",
              "198  11.831016  1.067704  2.089839  12.736121 -0.515204  4.795834  5.151528  \n",
              "199   9.940066 -0.008712  4.348502  12.988244 -0.612219  5.658818  6.789175  \n",
              "\n",
              "[200 rows x 1088 columns]"
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-fb4e98f3-71a0-4fa9-829f-3d2e2cd93c02\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>0</th>\n",
              "      <th>1</th>\n",
              "      <th>2</th>\n",
              "      <th>3</th>\n",
              "      <th>4</th>\n",
              "      <th>5</th>\n",
              "      <th>6</th>\n",
              "      <th>7</th>\n",
              "      <th>8</th>\n",
              "      <th>9</th>\n",
              "      <th>...</th>\n",
              "      <th>1078</th>\n",
              "      <th>1079</th>\n",
              "      <th>1080</th>\n",
              "      <th>1081</th>\n",
              "      <th>1082</th>\n",
              "      <th>1083</th>\n",
              "      <th>1084</th>\n",
              "      <th>1085</th>\n",
              "      <th>1086</th>\n",
              "      <th>1087</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.719750</td>\n",
              "      <td>1.295104</td>\n",
              "      <td>0.270759</td>\n",
              "      <td>-0.012204</td>\n",
              "      <td>2.155092</td>\n",
              "      <td>0.476580</td>\n",
              "      <td>-0.052861</td>\n",
              "      <td>4.335659</td>\n",
              "      <td>3.820559</td>\n",
              "      <td>1.658292</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.471146</td>\n",
              "      <td>-0.100195</td>\n",
              "      <td>17.739914</td>\n",
              "      <td>4.319383</td>\n",
              "      <td>4.136518</td>\n",
              "      <td>3.483100</td>\n",
              "      <td>14.281128</td>\n",
              "      <td>-0.402702</td>\n",
              "      <td>7.009530</td>\n",
              "      <td>7.430326</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.355583</td>\n",
              "      <td>6.395618</td>\n",
              "      <td>1.158820</td>\n",
              "      <td>-0.007579</td>\n",
              "      <td>0.325328</td>\n",
              "      <td>0.293184</td>\n",
              "      <td>-0.074968</td>\n",
              "      <td>10.191537</td>\n",
              "      <td>10.701912</td>\n",
              "      <td>1.583432</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.307946</td>\n",
              "      <td>-0.407126</td>\n",
              "      <td>13.410018</td>\n",
              "      <td>9.353767</td>\n",
              "      <td>1.683759</td>\n",
              "      <td>9.184101</td>\n",
              "      <td>8.624210</td>\n",
              "      <td>-0.652683</td>\n",
              "      <td>5.231555</td>\n",
              "      <td>6.766066</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.524714</td>\n",
              "      <td>2.672114</td>\n",
              "      <td>1.196146</td>\n",
              "      <td>0.008120</td>\n",
              "      <td>0.461488</td>\n",
              "      <td>0.417234</td>\n",
              "      <td>-0.081589</td>\n",
              "      <td>4.003283</td>\n",
              "      <td>3.449667</td>\n",
              "      <td>0.653876</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.100608</td>\n",
              "      <td>2.089319</td>\n",
              "      <td>5.718911</td>\n",
              "      <td>4.863150</td>\n",
              "      <td>1.414717</td>\n",
              "      <td>0.968559</td>\n",
              "      <td>7.228348</td>\n",
              "      <td>-0.174857</td>\n",
              "      <td>1.096362</td>\n",
              "      <td>2.670488</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>1.274993</td>\n",
              "      <td>2.302675</td>\n",
              "      <td>2.919310</td>\n",
              "      <td>0.566198</td>\n",
              "      <td>-0.001330</td>\n",
              "      <td>-0.071372</td>\n",
              "      <td>-0.013177</td>\n",
              "      <td>5.449011</td>\n",
              "      <td>11.848956</td>\n",
              "      <td>1.035774</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.130915</td>\n",
              "      <td>-0.077245</td>\n",
              "      <td>12.868748</td>\n",
              "      <td>8.057802</td>\n",
              "      <td>3.422311</td>\n",
              "      <td>-0.041648</td>\n",
              "      <td>4.870863</td>\n",
              "      <td>-0.154996</td>\n",
              "      <td>7.375211</td>\n",
              "      <td>2.683106</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>3.056850</td>\n",
              "      <td>9.784783</td>\n",
              "      <td>4.041884</td>\n",
              "      <td>2.785742</td>\n",
              "      <td>0.694391</td>\n",
              "      <td>0.036745</td>\n",
              "      <td>-0.098161</td>\n",
              "      <td>16.720371</td>\n",
              "      <td>19.554396</td>\n",
              "      <td>4.057654</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.865711</td>\n",
              "      <td>-0.096464</td>\n",
              "      <td>30.439096</td>\n",
              "      <td>8.097186</td>\n",
              "      <td>2.357097</td>\n",
              "      <td>6.244454</td>\n",
              "      <td>24.742315</td>\n",
              "      <td>-0.975386</td>\n",
              "      <td>4.698389</td>\n",
              "      <td>9.966484</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>...</th>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "      <td>...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>195</th>\n",
              "      <td>4.634676</td>\n",
              "      <td>8.718454</td>\n",
              "      <td>5.458107</td>\n",
              "      <td>0.836749</td>\n",
              "      <td>1.634265</td>\n",
              "      <td>0.159487</td>\n",
              "      <td>-0.107236</td>\n",
              "      <td>10.816562</td>\n",
              "      <td>19.774166</td>\n",
              "      <td>2.466617</td>\n",
              "      <td>...</td>\n",
              "      <td>0.851185</td>\n",
              "      <td>6.701710</td>\n",
              "      <td>8.501316</td>\n",
              "      <td>7.520336</td>\n",
              "      <td>-0.094893</td>\n",
              "      <td>1.861775</td>\n",
              "      <td>9.154671</td>\n",
              "      <td>-0.453004</td>\n",
              "      <td>-0.034368</td>\n",
              "      <td>3.734820</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>196</th>\n",
              "      <td>0.435286</td>\n",
              "      <td>5.644265</td>\n",
              "      <td>0.847490</td>\n",
              "      <td>0.064042</td>\n",
              "      <td>2.894183</td>\n",
              "      <td>0.580675</td>\n",
              "      <td>-0.056917</td>\n",
              "      <td>9.097086</td>\n",
              "      <td>9.307425</td>\n",
              "      <td>1.399802</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.465506</td>\n",
              "      <td>-0.132188</td>\n",
              "      <td>12.518223</td>\n",
              "      <td>7.247079</td>\n",
              "      <td>0.516293</td>\n",
              "      <td>5.981341</td>\n",
              "      <td>9.982636</td>\n",
              "      <td>-0.318908</td>\n",
              "      <td>4.652848</td>\n",
              "      <td>6.547028</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>197</th>\n",
              "      <td>0.706380</td>\n",
              "      <td>0.995824</td>\n",
              "      <td>0.737084</td>\n",
              "      <td>3.865249</td>\n",
              "      <td>-0.027228</td>\n",
              "      <td>0.846497</td>\n",
              "      <td>-0.036266</td>\n",
              "      <td>4.954056</td>\n",
              "      <td>6.965610</td>\n",
              "      <td>0.592042</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.196906</td>\n",
              "      <td>0.335270</td>\n",
              "      <td>9.476474</td>\n",
              "      <td>1.476306</td>\n",
              "      <td>0.884588</td>\n",
              "      <td>1.249459</td>\n",
              "      <td>10.813810</td>\n",
              "      <td>-0.293770</td>\n",
              "      <td>4.201102</td>\n",
              "      <td>3.899903</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>198</th>\n",
              "      <td>0.124875</td>\n",
              "      <td>4.242362</td>\n",
              "      <td>-0.027758</td>\n",
              "      <td>2.369631</td>\n",
              "      <td>-0.142721</td>\n",
              "      <td>0.463358</td>\n",
              "      <td>-0.023451</td>\n",
              "      <td>7.406272</td>\n",
              "      <td>5.642257</td>\n",
              "      <td>1.051440</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.177335</td>\n",
              "      <td>1.014689</td>\n",
              "      <td>15.748517</td>\n",
              "      <td>11.831016</td>\n",
              "      <td>1.067704</td>\n",
              "      <td>2.089839</td>\n",
              "      <td>12.736121</td>\n",
              "      <td>-0.515204</td>\n",
              "      <td>4.795834</td>\n",
              "      <td>5.151528</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>199</th>\n",
              "      <td>0.263641</td>\n",
              "      <td>0.178472</td>\n",
              "      <td>1.683303</td>\n",
              "      <td>-0.011357</td>\n",
              "      <td>1.979308</td>\n",
              "      <td>-0.060579</td>\n",
              "      <td>-0.060716</td>\n",
              "      <td>3.535658</td>\n",
              "      <td>2.827784</td>\n",
              "      <td>1.168633</td>\n",
              "      <td>...</td>\n",
              "      <td>-0.593845</td>\n",
              "      <td>-0.038523</td>\n",
              "      <td>17.085106</td>\n",
              "      <td>9.940066</td>\n",
              "      <td>-0.008712</td>\n",
              "      <td>4.348502</td>\n",
              "      <td>12.988244</td>\n",
              "      <td>-0.612219</td>\n",
              "      <td>5.658818</td>\n",
              "      <td>6.789175</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "<p>200 rows × 1088 columns</p>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-fb4e98f3-71a0-4fa9-829f-3d2e2cd93c02')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-fb4e98f3-71a0-4fa9-829f-3d2e2cd93c02 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-fb4e98f3-71a0-4fa9-829f-3d2e2cd93c02');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 50
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Deploy machine learning models on mobile devices\n",
        "\n",
        "\n",
        "Implement our deep learning models on ECGs collected via smartwatch, would help enabling screening very large patient populations for PD risk at a non-invasive and low-cost way.\n",
        "\n",
        "## TensorFlow Lite \n",
        "\n",
        "TensorFlow Lite is a mobile library for deploying models on mobile, microcontrollers and other edge devices.\n",
        "\n",
        "- Build a TensorFlow model (Keras Model using TF as a backend)\n",
        "- Convert TensorFlow model to TF-Lite\n",
        "- Deploy in the mobile app\n",
        "\n",
        "## ECG-Air App\n",
        "\n",
        "- Dr.Akbilgic and Conner Mccraw\n",
        "- The proposed HF model used\n",
        "- Building iOS app: in progress\n",
        "- Aim: Understand the reaction of Apple Watch ECG on TF model which built by using clinical ECG, we'll collect data from patients, first clinical ECG, and then subsequently Apple watch ECG.\n",
        "\n"
      ],
      "metadata": {
        "id": "Ha0tBCqqgMJC"
      },
      "id": "Ha0tBCqqgMJC"
    },
    {
      "cell_type": "code",
      "source": [
        "import glob\n",
        "print ('Models are loading..!')\n",
        "models = glob.glob('*.h5') #CNN models\n",
        "models"
      ],
      "metadata": {
        "id": "u39ks98sgK2z"
      },
      "id": "u39ks98sgK2z",
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import tensorflow as tf\n",
        "\n",
        "for i in range(len(models)):\n",
        "\n",
        "    #from tensorflow.contrib import lite \n",
        "    converter = tf.lite.TFLiteConverter.from_keras_model_file(models[i]) \n",
        "    model_name = 'TFLite' + models[i][:-3] + '.tflte'\n",
        "    tfmodel = converter.convert() \n",
        "    open (model_name , \"wb\") .write(tfmodel)"
      ],
      "metadata": {
        "id": "-TFQnMw7jI52"
      },
      "id": "-TFQnMw7jI52",
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3 (ipykernel)",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.7.7"
    },
    "colab": {
      "name": "Copy of DEMO-CoLab.ipynb",
      "provenance": [],
      "collapsed_sections": []
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}